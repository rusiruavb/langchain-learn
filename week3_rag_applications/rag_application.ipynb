{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 3: Advanced LangChain & RAG (Retrieval-Augmented Generation)\n",
    "\n",
    "## üìö Session Overview\n",
    "\n",
    "**Duration:** 2 hours  \n",
    "**Week:** 3  \n",
    "**Instructor-Led Session**\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Learning Objectives\n",
    "\n",
    "By the end of this session, you will be able to:\n",
    "1. Understand what RAG is and why it's important\n",
    "2. Work with embeddings and vector stores\n",
    "3. Set up and use PGVector for semantic search\n",
    "4. Process and chunk documents effectively\n",
    "5. Build complete RAG applications with LangChain\n",
    "6. Implement conversational RAG with memory\n",
    "\n",
    "---\n",
    "\n",
    "## üìã Prerequisites\n",
    "\n",
    "- ‚úÖ Completed Week 1 & 2\n",
    "- ‚úÖ Understanding of LangChain chains\n",
    "- ‚úÖ PostgreSQL with PGVector extension installed\n",
    "- ‚úÖ Docker running (for PGVector)\n",
    "\n",
    "---\n",
    "\n",
    "## ‚è±Ô∏è Estimated Time\n",
    "\n",
    "- Setup & Introduction: 10 minutes\n",
    "- Section 1 (RAG Introduction): 20 minutes\n",
    "- Section 2 (Embeddings & Vectors): 25 minutes\n",
    "- Section 3 (Document Processing): 20 minutes\n",
    "- Section 4 (Building RAG Apps): 35 minutes\n",
    "- Section 5 (Conversational RAG): 15 minutes\n",
    "- Wrap-up & Q&A: 5 minutes\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Setup complete!\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# LangChain imports\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import PGVector\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import TextLoader, PyPDFLoader\n",
    "from langchain_core.messages import BaseMessage, AIMessage, HumanMessage\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "\n",
    "# Standard imports\n",
    "from typing import List\n",
    "import textwrap\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "print(\"‚úÖ Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Section 1: Introduction to RAG (20 minutes)\n",
    "\n",
    "## What is RAG?\n",
    "\n",
    "**RAG (Retrieval-Augmented Generation)** combines the power of retrieval systems with generative AI.\n",
    "\n",
    "### The Problem RAG Solves\n",
    "\n",
    "**Without RAG:**\n",
    "- ‚ùå LLMs have a knowledge cutoff date\n",
    "- ‚ùå Can't access private/proprietary data\n",
    "- ‚ùå Limited by training data\n",
    "- ‚ùå May hallucinate facts\n",
    "\n",
    "**With RAG:**\n",
    "- ‚úÖ Access to current information\n",
    "- ‚úÖ Use your own documents/data\n",
    "- ‚úÖ Grounded, factual responses\n",
    "- ‚úÖ Cite sources\n",
    "\n",
    "---\n",
    "\n",
    "## How RAG Works\n",
    "\n",
    "```\n",
    "User Question\n",
    "     ‚Üì\n",
    "1. Convert to embedding (vector)\n",
    "     ‚Üì\n",
    "2. Search vector database for similar documents\n",
    "     ‚Üì\n",
    "3. Retrieve top K most relevant documents\n",
    "     ‚Üì\n",
    "4. Combine question + retrieved docs in prompt\n",
    "     ‚Üì\n",
    "5. LLM generates answer based on context\n",
    "     ‚Üì\n",
    "Answer with sources\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Key Components\n",
    "\n",
    "### 1. **Embeddings**\n",
    "- Convert text to numerical vectors (arrays of numbers)\n",
    "- Similar meaning = similar vectors\n",
    "- Example: OpenAI's `text-embedding-3-small` creates 1536-dimensional vectors\n",
    "\n",
    "### 2. **Vector Store**\n",
    "- Database optimized for vector similarity search\n",
    "- Examples: PGVector, Pinecone, Chroma, FAISS\n",
    "- We'll use **PGVector** (PostgreSQL extension)\n",
    "\n",
    "### 3. **Document Loaders**\n",
    "- Load documents from various sources\n",
    "- PDF, TXT, CSV, web pages, etc.\n",
    "\n",
    "### 4. **Text Splitters**\n",
    "- Break documents into smaller chunks\n",
    "- Preserve semantic meaning\n",
    "- Manage token limits\n",
    "\n",
    "### 5. **Retriever**\n",
    "- Searches vector store\n",
    "- Returns most relevant chunks\n",
    "\n",
    "---\n",
    "\n",
    "## Use Cases\n",
    "\n",
    "- **Customer Support:** Answer questions from documentation\n",
    "- **Research Assistant:** Search through papers/articles\n",
    "- **Internal Knowledge Base:** Company policies, procedures\n",
    "- **Legal/Compliance:** Search contracts and regulations\n",
    "- **Code Assistant:** Search codebase and documentation\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Section 2: Embeddings & Vector Stores (25 minutes)\n",
    "\n",
    "## Understanding Embeddings\n",
    "\n",
    "Embeddings are **numerical representations** of text that capture semantic meaning.\n",
    "\n",
    "### How Embeddings Work\n",
    "\n",
    "```python\n",
    "Text: \"The cat sits on the mat\"\n",
    "     ‚Üì (Embedding Model)\n",
    "Vector: [0.23, -0.45, 0.67, ..., 0.12]  # 1536 numbers\n",
    "```\n",
    "\n",
    "**Similar texts ‚Üí Similar vectors:**\n",
    "```\n",
    "\"cat on mat\"     ‚Üí [0.23, -0.45, 0.67, ...]\n",
    "\"feline on rug\"  ‚Üí [0.25, -0.43, 0.69, ...]  # Very similar!\n",
    "\"car in garage\"  ‚Üí [0.89, 0.12, -0.34, ...]  # Very different!\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1: Creating Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Embedding Info:\n",
      "Text: What is artificial intelligence?\n",
      "Vector dimension: 1536\n",
      "First 10 values: [0.006162669975310564, -0.01451562624424696, -0.03586096316576004, 0.0057395463809370995, 0.021922778338193893, -0.037055667489767075, -0.03623928874731064, 0.014804346486926079, -0.01701454445719719, 0.023894036188721657]\n",
      "Vector type: <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# Initialize embedding model\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\",\n",
    "    openai_api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    ")\n",
    "\n",
    "# Create embedding for a single text\n",
    "text = \"What is artificial intelligence?\"\n",
    "embedding_vector = embeddings.embed_query(text)\n",
    "\n",
    "print(\"üìä Embedding Info:\")\n",
    "print(f\"Text: {text}\")\n",
    "print(f\"Vector dimension: {len(embedding_vector)}\")\n",
    "print(f\"First 10 values: {embedding_vector[:10]}\")\n",
    "print(f\"Vector type: {type(embedding_vector)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding Multiple Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìö Embedded 3 documents\n",
      "Each embedding has 1536 dimensions\n"
     ]
    }
   ],
   "source": [
    "# Embed multiple documents\n",
    "documents = [\n",
    "    \"Python is a programming language.\",\n",
    "    \"Machine learning is a subset of AI.\",\n",
    "    \"Neural networks are inspired by the human brain.\"\n",
    "]\n",
    "\n",
    "doc_embeddings = embeddings.embed_documents(documents)\n",
    "\n",
    "print(f\"üìö Embedded {len(doc_embeddings)} documents\")\n",
    "print(f\"Each embedding has {len(doc_embeddings[0])} dimensions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity Between Embeddings\n",
    "\n",
    "We can measure similarity using **cosine similarity** or **dot product**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Similarity Scores:\n",
      "Text 1 vs Text 2 (similar): 0.6870\n",
      "Text 1 vs Text 3 (different): 0.3085\n",
      "Text 2 vs Text 3 (different): 0.3102\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    \"\"\"Calculate cosine similarity between two vectors.\"\"\"\n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "    norm1 = np.linalg.norm(vec1)\n",
    "    norm2 = np.linalg.norm(vec2)\n",
    "    return dot_product / (norm1 * norm2)\n",
    "\n",
    "# Compare similarities\n",
    "texts = [\n",
    "    \"I love programming in Python\",\n",
    "    \"Python is my favorite coding language\",\n",
    "    \"I enjoy eating pizza\"\n",
    "]\n",
    "\n",
    "vecs = [embeddings.embed_query(t) for t in texts]\n",
    "\n",
    "print(\"üîç Similarity Scores:\")\n",
    "print(f\"Text 1 vs Text 2 (similar): {cosine_similarity(vecs[0], vecs[1]):.4f}\")\n",
    "print(f\"Text 1 vs Text 3 (different): {cosine_similarity(vecs[0], vecs[2]):.4f}\")\n",
    "print(f\"Text 2 vs Text 3 (different): {cosine_similarity(vecs[1], vecs[2]):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2.2: Setting Up PGVector\n",
    "\n",
    "**PGVector** is a PostgreSQL extension for storing and searching vector embeddings.\n",
    "\n",
    "### Why PGVector?\n",
    "\n",
    "- ‚úÖ Built on reliable PostgreSQL\n",
    "- ‚úÖ ACID compliance (transactions)\n",
    "- ‚úÖ Can store vectors alongside regular data\n",
    "- ‚úÖ Fast similarity search\n",
    "- ‚úÖ Open source and free\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize PGVector Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Connection string configured\n",
      "üì¶ Collection name: week3_demo\n"
     ]
    }
   ],
   "source": [
    "# Database connection string\n",
    "# Format: postgresql://username:password@host:port/database\n",
    "CONNECTION_STRING = os.getenv(\n",
    "    \"DATABASE_URL\",\n",
    "    \"postgresql://postgres:postgres@localhost:5432/ai_agent_course\"\n",
    ")\n",
    "\n",
    "# Collection name (like a table for this use case)\n",
    "COLLECTION_NAME = \"week3_demo\"\n",
    "\n",
    "print(f\"‚úÖ Connection string configured\")\n",
    "print(f\"üì¶ Collection name: {COLLECTION_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store Documents in PGVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rusirubandara/Documents/code/wireapps/intern/ai-program/venv/lib/python3.11/site-packages/langchain_community/vectorstores/pgvector.py:490: LangChainPendingDeprecationWarning: Please use JSONB instead of JSON for metadata. This change will allow for more efficient querying that involves filtering based on metadata. Please note that filtering operators have been changed when using JSONB metadata to be prefixed with a $ sign to avoid name collisions with columns. If you're using an existing database, you will need to create a db migration for your metadata column to be JSONB and update your queries to use the new operators. \n",
      "  store = cls(\n",
      "Exception ignored in: <function PGVector.__del__ at 0x111467e20>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rusirubandara/Documents/code/wireapps/intern/ai-program/venv/lib/python3.11/site-packages/langchain_community/vectorstores/pgvector.py\", line 368, in __del__\n",
      "AttributeError: 'PGVector' object has no attribute '_bind'\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Failed to create vector extension: (psycopg2.OperationalError) connection to server at \"localhost\" (::1), port 5432 failed: FATAL:  database \"ai_agent_course\" does not exist\n\n(Background on this error at: https://sqlalche.me/e/20/e3q8)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOperationalError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/code/wireapps/intern/ai-program/venv/lib/python3.11/site-packages/sqlalchemy/engine/base.py:143\u001b[39m, in \u001b[36mConnection.__init__\u001b[39m\u001b[34m(self, engine, connection, _has_events, _allow_revalidate, _allow_autobegin)\u001b[39m\n\u001b[32m    142\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m143\u001b[39m     \u001b[38;5;28mself\u001b[39m._dbapi_connection = \u001b[43mengine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraw_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    144\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m dialect.loaded_dbapi.Error \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/code/wireapps/intern/ai-program/venv/lib/python3.11/site-packages/sqlalchemy/engine/base.py:3309\u001b[39m, in \u001b[36mEngine.raw_connection\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   3288\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Return a \"raw\" DBAPI connection from the connection pool.\u001b[39;00m\n\u001b[32m   3289\u001b[39m \n\u001b[32m   3290\u001b[39m \u001b[33;03mThe returned object is a proxied version of the DBAPI\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   3307\u001b[39m \n\u001b[32m   3308\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3309\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/code/wireapps/intern/ai-program/venv/lib/python3.11/site-packages/sqlalchemy/pool/base.py:447\u001b[39m, in \u001b[36mPool.connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    440\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Return a DBAPI connection from the pool.\u001b[39;00m\n\u001b[32m    441\u001b[39m \n\u001b[32m    442\u001b[39m \u001b[33;03mThe connection is instrumented such that when its\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    445\u001b[39m \n\u001b[32m    446\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m447\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ConnectionFairy\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_checkout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/code/wireapps/intern/ai-program/venv/lib/python3.11/site-packages/sqlalchemy/pool/base.py:1264\u001b[39m, in \u001b[36m_ConnectionFairy._checkout\u001b[39m\u001b[34m(cls, pool, threadconns, fairy)\u001b[39m\n\u001b[32m   1263\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fairy:\n\u001b[32m-> \u001b[39m\u001b[32m1264\u001b[39m     fairy = \u001b[43m_ConnectionRecord\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcheckout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpool\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1266\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m threadconns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/code/wireapps/intern/ai-program/venv/lib/python3.11/site-packages/sqlalchemy/pool/base.py:711\u001b[39m, in \u001b[36m_ConnectionRecord.checkout\u001b[39m\u001b[34m(cls, pool)\u001b[39m\n\u001b[32m    710\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m711\u001b[39m     rec = \u001b[43mpool\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_do_get\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    713\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/code/wireapps/intern/ai-program/venv/lib/python3.11/site-packages/sqlalchemy/pool/impl.py:177\u001b[39m, in \u001b[36mQueuePool._do_get\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mutil\u001b[49m\u001b[43m.\u001b[49m\u001b[43msafe_reraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dec_overflow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/code/wireapps/intern/ai-program/venv/lib/python3.11/site-packages/sqlalchemy/util/langhelpers.py:224\u001b[39m, in \u001b[36msafe_reraise.__exit__\u001b[39m\u001b[34m(self, type_, value, traceback)\u001b[39m\n\u001b[32m    223\u001b[39m     \u001b[38;5;28mself\u001b[39m._exc_info = \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m224\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc_value.with_traceback(exc_tb)\n\u001b[32m    225\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/code/wireapps/intern/ai-program/venv/lib/python3.11/site-packages/sqlalchemy/pool/impl.py:175\u001b[39m, in \u001b[36mQueuePool._do_get\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    174\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m175\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/code/wireapps/intern/ai-program/venv/lib/python3.11/site-packages/sqlalchemy/pool/base.py:388\u001b[39m, in \u001b[36mPool._create_connection\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    386\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Called by subclasses to create a new ConnectionRecord.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m388\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ConnectionRecord\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/code/wireapps/intern/ai-program/venv/lib/python3.11/site-packages/sqlalchemy/pool/base.py:673\u001b[39m, in \u001b[36m_ConnectionRecord.__init__\u001b[39m\u001b[34m(self, pool, connect)\u001b[39m\n\u001b[32m    672\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m connect:\n\u001b[32m--> \u001b[39m\u001b[32m673\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__connect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[38;5;28mself\u001b[39m.finalize_callback = deque()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/code/wireapps/intern/ai-program/venv/lib/python3.11/site-packages/sqlalchemy/pool/base.py:899\u001b[39m, in \u001b[36m_ConnectionRecord.__connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    898\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m899\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mutil\u001b[49m\u001b[43m.\u001b[49m\u001b[43msafe_reraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    900\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlogger\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mError on connect(): \u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/code/wireapps/intern/ai-program/venv/lib/python3.11/site-packages/sqlalchemy/util/langhelpers.py:224\u001b[39m, in \u001b[36msafe_reraise.__exit__\u001b[39m\u001b[34m(self, type_, value, traceback)\u001b[39m\n\u001b[32m    223\u001b[39m     \u001b[38;5;28mself\u001b[39m._exc_info = \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m224\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc_value.with_traceback(exc_tb)\n\u001b[32m    225\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/code/wireapps/intern/ai-program/venv/lib/python3.11/site-packages/sqlalchemy/pool/base.py:895\u001b[39m, in \u001b[36m_ConnectionRecord.__connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    894\u001b[39m \u001b[38;5;28mself\u001b[39m.starttime = time.time()\n\u001b[32m--> \u001b[39m\u001b[32m895\u001b[39m \u001b[38;5;28mself\u001b[39m.dbapi_connection = connection = \u001b[43mpool\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_invoke_creator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    896\u001b[39m pool.logger.debug(\u001b[33m\"\u001b[39m\u001b[33mCreated new connection \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m\"\u001b[39m, connection)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/code/wireapps/intern/ai-program/venv/lib/python3.11/site-packages/sqlalchemy/engine/create.py:661\u001b[39m, in \u001b[36mcreate_engine.<locals>.connect\u001b[39m\u001b[34m(connection_record)\u001b[39m\n\u001b[32m    659\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m connection\n\u001b[32m--> \u001b[39m\u001b[32m661\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdialect\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/code/wireapps/intern/ai-program/venv/lib/python3.11/site-packages/sqlalchemy/engine/default.py:630\u001b[39m, in \u001b[36mDefaultDialect.connect\u001b[39m\u001b[34m(self, *cargs, **cparams)\u001b[39m\n\u001b[32m    628\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m, *cargs: Any, **cparams: Any) -> DBAPIConnection:\n\u001b[32m    629\u001b[39m     \u001b[38;5;66;03m# inherits the docstring from interfaces.Dialect.connect\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m630\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mloaded_dbapi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/code/wireapps/intern/ai-program/venv/lib/python3.11/site-packages/psycopg2/__init__.py:122\u001b[39m, in \u001b[36mconnect\u001b[39m\u001b[34m(dsn, connection_factory, cursor_factory, **kwargs)\u001b[39m\n\u001b[32m    121\u001b[39m dsn = _ext.make_dsn(dsn, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m conn = \u001b[43m_connect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdsn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconnection_factory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconnection_factory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwasync\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cursor_factory \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mOperationalError\u001b[39m: connection to server at \"localhost\" (::1), port 5432 failed: FATAL:  database \"ai_agent_course\" does not exist\n",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mOperationalError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/code/wireapps/intern/ai-program/venv/lib/python3.11/site-packages/langchain_community/vectorstores/pgvector.py:392\u001b[39m, in \u001b[36mPGVector.create_vector_extension\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    386\u001b[39m statement = sqlalchemy.text(\n\u001b[32m    387\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mBEGIN;\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    388\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mSELECT pg_advisory_xact_lock(1573678846307946496);\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    389\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mCREATE EXTENSION IF NOT EXISTS vector;\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    390\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mCOMMIT;\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    391\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m392\u001b[39m \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    393\u001b[39m session.commit()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/code/wireapps/intern/ai-program/venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py:2351\u001b[39m, in \u001b[36mSession.execute\u001b[39m\u001b[34m(self, statement, params, execution_options, bind_arguments, _parent_execute_state, _add_event)\u001b[39m\n\u001b[32m   2301\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Execute a SQL expression construct.\u001b[39;00m\n\u001b[32m   2302\u001b[39m \n\u001b[32m   2303\u001b[39m \u001b[33;03mReturns a :class:`_engine.Result` object representing\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   2349\u001b[39m \n\u001b[32m   2350\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2351\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute_internal\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2352\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2353\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2354\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbind_arguments\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbind_arguments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2356\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_parent_execute_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_parent_execute_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2357\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_add_event\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_add_event\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2358\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/code/wireapps/intern/ai-program/venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py:2239\u001b[39m, in \u001b[36mSession._execute_internal\u001b[39m\u001b[34m(self, statement, params, execution_options, bind_arguments, _parent_execute_state, _add_event, _scalar_result)\u001b[39m\n\u001b[32m   2237\u001b[39m bind = \u001b[38;5;28mself\u001b[39m.get_bind(**bind_arguments)\n\u001b[32m-> \u001b[39m\u001b[32m2239\u001b[39m conn = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connection_for_bind\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbind\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2241\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _scalar_result \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m compile_state_cls:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/code/wireapps/intern/ai-program/venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py:2108\u001b[39m, in \u001b[36mSession._connection_for_bind\u001b[39m\u001b[34m(self, engine, execution_options, **kw)\u001b[39m\n\u001b[32m   2107\u001b[39m     trans = \u001b[38;5;28mself\u001b[39m._autobegin_t()\n\u001b[32m-> \u001b[39m\u001b[32m2108\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrans\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_connection_for_bind\u001b[49m\u001b[43m(\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<string>:2\u001b[39m, in \u001b[36m_connection_for_bind\u001b[39m\u001b[34m(self, bind, execution_options)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/code/wireapps/intern/ai-program/venv/lib/python3.11/site-packages/sqlalchemy/orm/state_changes.py:137\u001b[39m, in \u001b[36m_StateChange.declare_states.<locals>._go\u001b[39m\u001b[34m(fn, self, *arg, **kw)\u001b[39m\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m     ret_value = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/code/wireapps/intern/ai-program/venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py:1187\u001b[39m, in \u001b[36mSessionTransaction._connection_for_bind\u001b[39m\u001b[34m(self, bind, execution_options)\u001b[39m\n\u001b[32m   1186\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1187\u001b[39m     conn = \u001b[43mbind\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1188\u001b[39m     local_connect = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/code/wireapps/intern/ai-program/venv/lib/python3.11/site-packages/sqlalchemy/engine/base.py:3285\u001b[39m, in \u001b[36mEngine.connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   3263\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Return a new :class:`_engine.Connection` object.\u001b[39;00m\n\u001b[32m   3264\u001b[39m \n\u001b[32m   3265\u001b[39m \u001b[33;03mThe :class:`_engine.Connection` acts as a Python context manager, so\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   3282\u001b[39m \n\u001b[32m   3283\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3285\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connection_cls\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/code/wireapps/intern/ai-program/venv/lib/python3.11/site-packages/sqlalchemy/engine/base.py:145\u001b[39m, in \u001b[36mConnection.__init__\u001b[39m\u001b[34m(self, engine, connection, _has_events, _allow_revalidate, _allow_autobegin)\u001b[39m\n\u001b[32m    144\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m dialect.loaded_dbapi.Error \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m--> \u001b[39m\u001b[32m145\u001b[39m     \u001b[43mConnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_handle_dbapi_exception_noconnection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    146\u001b[39m \u001b[43m        \u001b[49m\u001b[43merr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\n\u001b[32m    147\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    148\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/code/wireapps/intern/ai-program/venv/lib/python3.11/site-packages/sqlalchemy/engine/base.py:2448\u001b[39m, in \u001b[36mConnection._handle_dbapi_exception_noconnection\u001b[39m\u001b[34m(cls, e, dialect, engine, is_disconnect, invalidate_pool_on_disconnect, is_pre_ping)\u001b[39m\n\u001b[32m   2447\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m sqlalchemy_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2448\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m sqlalchemy_exception.with_traceback(exc_info[\u001b[32m2\u001b[39m]) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m   2449\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/code/wireapps/intern/ai-program/venv/lib/python3.11/site-packages/sqlalchemy/engine/base.py:143\u001b[39m, in \u001b[36mConnection.__init__\u001b[39m\u001b[34m(self, engine, connection, _has_events, _allow_revalidate, _allow_autobegin)\u001b[39m\n\u001b[32m    142\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m143\u001b[39m     \u001b[38;5;28mself\u001b[39m._dbapi_connection = \u001b[43mengine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraw_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    144\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m dialect.loaded_dbapi.Error \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/code/wireapps/intern/ai-program/venv/lib/python3.11/site-packages/sqlalchemy/engine/base.py:3309\u001b[39m, in \u001b[36mEngine.raw_connection\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   3288\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Return a \"raw\" DBAPI connection from the connection pool.\u001b[39;00m\n\u001b[32m   3289\u001b[39m \n\u001b[32m   3290\u001b[39m \u001b[33;03mThe returned object is a proxied version of the DBAPI\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   3307\u001b[39m \n\u001b[32m   3308\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3309\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/code/wireapps/intern/ai-program/venv/lib/python3.11/site-packages/sqlalchemy/pool/base.py:447\u001b[39m, in \u001b[36mPool.connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    440\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Return a DBAPI connection from the pool.\u001b[39;00m\n\u001b[32m    441\u001b[39m \n\u001b[32m    442\u001b[39m \u001b[33;03mThe connection is instrumented such that when its\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    445\u001b[39m \n\u001b[32m    446\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m447\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ConnectionFairy\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_checkout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/code/wireapps/intern/ai-program/venv/lib/python3.11/site-packages/sqlalchemy/pool/base.py:1264\u001b[39m, in \u001b[36m_ConnectionFairy._checkout\u001b[39m\u001b[34m(cls, pool, threadconns, fairy)\u001b[39m\n\u001b[32m   1263\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fairy:\n\u001b[32m-> \u001b[39m\u001b[32m1264\u001b[39m     fairy = \u001b[43m_ConnectionRecord\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcheckout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpool\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1266\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m threadconns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/code/wireapps/intern/ai-program/venv/lib/python3.11/site-packages/sqlalchemy/pool/base.py:711\u001b[39m, in \u001b[36m_ConnectionRecord.checkout\u001b[39m\u001b[34m(cls, pool)\u001b[39m\n\u001b[32m    710\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m711\u001b[39m     rec = \u001b[43mpool\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_do_get\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    713\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/code/wireapps/intern/ai-program/venv/lib/python3.11/site-packages/sqlalchemy/pool/impl.py:177\u001b[39m, in \u001b[36mQueuePool._do_get\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mutil\u001b[49m\u001b[43m.\u001b[49m\u001b[43msafe_reraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dec_overflow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/code/wireapps/intern/ai-program/venv/lib/python3.11/site-packages/sqlalchemy/util/langhelpers.py:224\u001b[39m, in \u001b[36msafe_reraise.__exit__\u001b[39m\u001b[34m(self, type_, value, traceback)\u001b[39m\n\u001b[32m    223\u001b[39m     \u001b[38;5;28mself\u001b[39m._exc_info = \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m224\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc_value.with_traceback(exc_tb)\n\u001b[32m    225\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/code/wireapps/intern/ai-program/venv/lib/python3.11/site-packages/sqlalchemy/pool/impl.py:175\u001b[39m, in \u001b[36mQueuePool._do_get\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    174\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m175\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/code/wireapps/intern/ai-program/venv/lib/python3.11/site-packages/sqlalchemy/pool/base.py:388\u001b[39m, in \u001b[36mPool._create_connection\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    386\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Called by subclasses to create a new ConnectionRecord.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m388\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ConnectionRecord\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/code/wireapps/intern/ai-program/venv/lib/python3.11/site-packages/sqlalchemy/pool/base.py:673\u001b[39m, in \u001b[36m_ConnectionRecord.__init__\u001b[39m\u001b[34m(self, pool, connect)\u001b[39m\n\u001b[32m    672\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m connect:\n\u001b[32m--> \u001b[39m\u001b[32m673\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__connect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[38;5;28mself\u001b[39m.finalize_callback = deque()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/code/wireapps/intern/ai-program/venv/lib/python3.11/site-packages/sqlalchemy/pool/base.py:899\u001b[39m, in \u001b[36m_ConnectionRecord.__connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    898\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m899\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mutil\u001b[49m\u001b[43m.\u001b[49m\u001b[43msafe_reraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    900\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlogger\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mError on connect(): \u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/code/wireapps/intern/ai-program/venv/lib/python3.11/site-packages/sqlalchemy/util/langhelpers.py:224\u001b[39m, in \u001b[36msafe_reraise.__exit__\u001b[39m\u001b[34m(self, type_, value, traceback)\u001b[39m\n\u001b[32m    223\u001b[39m     \u001b[38;5;28mself\u001b[39m._exc_info = \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m224\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc_value.with_traceback(exc_tb)\n\u001b[32m    225\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/code/wireapps/intern/ai-program/venv/lib/python3.11/site-packages/sqlalchemy/pool/base.py:895\u001b[39m, in \u001b[36m_ConnectionRecord.__connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    894\u001b[39m \u001b[38;5;28mself\u001b[39m.starttime = time.time()\n\u001b[32m--> \u001b[39m\u001b[32m895\u001b[39m \u001b[38;5;28mself\u001b[39m.dbapi_connection = connection = \u001b[43mpool\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_invoke_creator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    896\u001b[39m pool.logger.debug(\u001b[33m\"\u001b[39m\u001b[33mCreated new connection \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m\"\u001b[39m, connection)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/code/wireapps/intern/ai-program/venv/lib/python3.11/site-packages/sqlalchemy/engine/create.py:661\u001b[39m, in \u001b[36mcreate_engine.<locals>.connect\u001b[39m\u001b[34m(connection_record)\u001b[39m\n\u001b[32m    659\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m connection\n\u001b[32m--> \u001b[39m\u001b[32m661\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdialect\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/code/wireapps/intern/ai-program/venv/lib/python3.11/site-packages/sqlalchemy/engine/default.py:630\u001b[39m, in \u001b[36mDefaultDialect.connect\u001b[39m\u001b[34m(self, *cargs, **cparams)\u001b[39m\n\u001b[32m    628\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m, *cargs: Any, **cparams: Any) -> DBAPIConnection:\n\u001b[32m    629\u001b[39m     \u001b[38;5;66;03m# inherits the docstring from interfaces.Dialect.connect\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m630\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mloaded_dbapi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/code/wireapps/intern/ai-program/venv/lib/python3.11/site-packages/psycopg2/__init__.py:122\u001b[39m, in \u001b[36mconnect\u001b[39m\u001b[34m(dsn, connection_factory, cursor_factory, **kwargs)\u001b[39m\n\u001b[32m    121\u001b[39m dsn = _ext.make_dsn(dsn, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m conn = \u001b[43m_connect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdsn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconnection_factory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconnection_factory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwasync\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cursor_factory \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mOperationalError\u001b[39m: (psycopg2.OperationalError) connection to server at \"localhost\" (::1), port 5432 failed: FATAL:  database \"ai_agent_course\" does not exist\n\n(Background on this error at: https://sqlalche.me/e/20/e3q8)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mException\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 24\u001b[39m\n\u001b[32m      4\u001b[39m sample_docs = [\n\u001b[32m      5\u001b[39m     Document(\n\u001b[32m      6\u001b[39m         page_content=\u001b[33m\"\u001b[39m\u001b[33mPython is a high-level programming language known for its simplicity.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     20\u001b[39m     )\n\u001b[32m     21\u001b[39m ]\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# Create vector store and add documents\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m vectorstore = \u001b[43mPGVector\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_docs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m=\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCOLLECTION_NAME\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconnection_string\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCONNECTION_STRING\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m‚úÖ Stored \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(sample_docs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m documents in PGVector\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/code/wireapps/intern/ai-program/venv/lib/python3.11/site-packages/langchain_community/vectorstores/pgvector.py:1149\u001b[39m, in \u001b[36mPGVector.from_documents\u001b[39m\u001b[34m(cls, documents, embedding, collection_name, distance_strategy, ids, pre_delete_collection, use_jsonb, **kwargs)\u001b[39m\n\u001b[32m   1145\u001b[39m connection_string = \u001b[38;5;28mcls\u001b[39m.get_connection_string(kwargs)\n\u001b[32m   1147\u001b[39m kwargs[\u001b[33m\"\u001b[39m\u001b[33mconnection_string\u001b[39m\u001b[33m\"\u001b[39m] = connection_string\n\u001b[32m-> \u001b[39m\u001b[32m1149\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfrom_texts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1150\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1151\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpre_delete_collection\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpre_delete_collection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1152\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m=\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1153\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdistance_strategy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdistance_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1154\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1155\u001b[39m \u001b[43m    \u001b[49m\u001b[43mids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1156\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1157\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_jsonb\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_jsonb\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1158\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1159\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/code/wireapps/intern/ai-program/venv/lib/python3.11/site-packages/langchain_community/vectorstores/pgvector.py:1021\u001b[39m, in \u001b[36mPGVector.from_texts\u001b[39m\u001b[34m(cls, texts, embedding, metadatas, collection_name, distance_strategy, ids, pre_delete_collection, use_jsonb, **kwargs)\u001b[39m\n\u001b[32m   1013\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1014\u001b[39m \u001b[33;03mReturn VectorStore initialized from texts and embeddings.\u001b[39;00m\n\u001b[32m   1015\u001b[39m \u001b[33;03mPostgres connection string is required\u001b[39;00m\n\u001b[32m   1016\u001b[39m \u001b[33;03m\"Either pass it as a parameter\u001b[39;00m\n\u001b[32m   1017\u001b[39m \u001b[33;03mor set the PGVECTOR_CONNECTION_STRING environment variable.\u001b[39;00m\n\u001b[32m   1018\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1019\u001b[39m embeddings = embedding.embed_documents(\u001b[38;5;28mlist\u001b[39m(texts))\n\u001b[32m-> \u001b[39m\u001b[32m1021\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_from\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1022\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1023\u001b[39m \u001b[43m    \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1024\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1025\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1026\u001b[39m \u001b[43m    \u001b[49m\u001b[43mids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1027\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1028\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdistance_strategy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdistance_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1029\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpre_delete_collection\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpre_delete_collection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1030\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_jsonb\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_jsonb\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1031\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1032\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/code/wireapps/intern/ai-program/venv/lib/python3.11/site-packages/langchain_community/vectorstores/pgvector.py:490\u001b[39m, in \u001b[36mPGVector._from\u001b[39m\u001b[34m(cls, texts, embeddings, embedding, metadatas, ids, collection_name, distance_strategy, connection_string, pre_delete_collection, use_jsonb, **kwargs)\u001b[39m\n\u001b[32m    487\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m connection_string \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    488\u001b[39m     connection_string = \u001b[38;5;28mcls\u001b[39m.get_connection_string(kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m490\u001b[39m store = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconnection_string\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconnection_string\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding_function\u001b[49m\u001b[43m=\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdistance_strategy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdistance_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpre_delete_collection\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpre_delete_collection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_jsonb\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_jsonb\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    500\u001b[39m store.add_embeddings(\n\u001b[32m    501\u001b[39m     texts=texts, embeddings=embeddings, metadatas=metadatas, ids=ids, **kwargs\n\u001b[32m    502\u001b[39m )\n\u001b[32m    504\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m store\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/code/wireapps/intern/ai-program/venv/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:221\u001b[39m, in \u001b[36mdeprecated.<locals>.deprecate.<locals>.finalize.<locals>.warn_if_direct_instance\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    219\u001b[39m     warned = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    220\u001b[39m     emit_warning()\n\u001b[32m--> \u001b[39m\u001b[32m221\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/code/wireapps/intern/ai-program/venv/lib/python3.11/site-packages/langchain_community/vectorstores/pgvector.py:350\u001b[39m, in \u001b[36mPGVector.__init__\u001b[39m\u001b[34m(self, connection_string, embedding_function, embedding_length, collection_name, collection_metadata, distance_strategy, pre_delete_collection, logger, relevance_score_fn, connection, engine_args, use_jsonb, create_extension)\u001b[39m\n\u001b[32m    329\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m use_jsonb:\n\u001b[32m    330\u001b[39m     \u001b[38;5;66;03m# Replace with a deprecation warning.\u001b[39;00m\n\u001b[32m    331\u001b[39m     warn_deprecated(\n\u001b[32m    332\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m0.0.29\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    333\u001b[39m         pending=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    348\u001b[39m         ),\n\u001b[32m    349\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m350\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__post_init__\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/code/wireapps/intern/ai-program/venv/lib/python3.11/site-packages/langchain_community/vectorstores/pgvector.py:357\u001b[39m, in \u001b[36mPGVector.__post_init__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    355\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Initialize the store.\"\"\"\u001b[39;00m\n\u001b[32m    356\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.create_extension:\n\u001b[32m--> \u001b[39m\u001b[32m357\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcreate_vector_extension\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    359\u001b[39m EmbeddingStore, CollectionStore = _get_embedding_collection_store(\n\u001b[32m    360\u001b[39m     \u001b[38;5;28mself\u001b[39m._embedding_length, use_jsonb=\u001b[38;5;28mself\u001b[39m.use_jsonb\n\u001b[32m    361\u001b[39m )\n\u001b[32m    362\u001b[39m \u001b[38;5;28mself\u001b[39m.CollectionStore = CollectionStore\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/code/wireapps/intern/ai-program/venv/lib/python3.11/site-packages/langchain_community/vectorstores/pgvector.py:395\u001b[39m, in \u001b[36mPGVector.create_vector_extension\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    393\u001b[39m         session.commit()\n\u001b[32m    394\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m395\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to create vector extension: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
      "\u001b[31mException\u001b[39m: Failed to create vector extension: (psycopg2.OperationalError) connection to server at \"localhost\" (::1), port 5432 failed: FATAL:  database \"ai_agent_course\" does not exist\n\n(Background on this error at: https://sqlalche.me/e/20/e3q8)"
     ]
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "# Create sample documents\n",
    "sample_docs = [\n",
    "    Document(\n",
    "        page_content=\"Python is a high-level programming language known for its simplicity.\",\n",
    "        metadata={\"source\": \"python_intro.txt\", \"category\": \"programming\"}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Machine learning enables computers to learn from data without explicit programming.\",\n",
    "        metadata={\"source\": \"ml_basics.txt\", \"category\": \"AI\"}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"LangChain is a framework for developing applications powered by language models.\",\n",
    "        metadata={\"source\": \"langchain_docs.txt\", \"category\": \"framework\"}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Vector databases store embeddings and enable semantic search capabilities.\",\n",
    "        metadata={\"source\": \"vector_db.txt\", \"category\": \"database\"}\n",
    "    )\n",
    "]\n",
    "\n",
    "# Create vector store and add documents\n",
    "vectorstore = PGVector.from_documents(\n",
    "    documents=sample_docs,\n",
    "    embedding=embeddings,\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    connection_string=CONNECTION_STRING,\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Stored {len(sample_docs)} documents in PGVector\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search Vector Store (Similarity Search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform similarity search\n",
    "query = \"What is a framework for building AI applications?\"\n",
    "\n",
    "results = vectorstore.similarity_search(query, k=2)\n",
    "\n",
    "print(f\"üîç Query: {query}\")\n",
    "print(f\"\\nüìä Top {len(results)} Results:\\n\")\n",
    "\n",
    "for i, doc in enumerate(results, 1):\n",
    "    print(f\"{i}. {doc.page_content}\")\n",
    "    print(f\"   Source: {doc.metadata['source']}\")\n",
    "    print(f\"   Category: {doc.metadata['category']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity Search with Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get similarity scores\n",
    "results_with_scores = vectorstore.similarity_search_with_score(query, k=3)\n",
    "\n",
    "print(f\"üîç Query: {query}\")\n",
    "print(f\"\\nüìä Results with Similarity Scores:\\n\")\n",
    "\n",
    "for doc, score in results_with_scores:\n",
    "    print(f\"Score: {score:.4f}\")\n",
    "    print(f\"Content: {doc.page_content}\")\n",
    "    print(f\"Source: {doc.metadata['source']}\")\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter by Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search with metadata filter\n",
    "filtered_results = vectorstore.similarity_search(\n",
    "    query=\"programming\",\n",
    "    k=5,\n",
    "    filter={\"category\": \"programming\"}\n",
    ")\n",
    "\n",
    "print(\"üîç Filtered Search (category='programming'):\")\n",
    "for doc in filtered_results:\n",
    "    print(f\"- {doc.page_content}\")\n",
    "    print(f\"  Category: {doc.metadata['category']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Section 3: Document Processing (20 minutes)\n",
    "\n",
    "## Why Document Processing Matters\n",
    "\n",
    "**Challenges:**\n",
    "- Documents are often too long for LLM context windows\n",
    "- Need to break into meaningful chunks\n",
    "- Must preserve context and relationships\n",
    "- Different file formats require different handling\n",
    "\n",
    "**Solution:**\n",
    "- **Document Loaders:** Extract text from various formats\n",
    "- **Text Splitters:** Intelligently chunk documents\n",
    "- **Metadata:** Track source and context\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1: Document Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample text file\n",
    "sample_text = \"\"\"\n",
    "Introduction to Artificial Intelligence\n",
    "\n",
    "Artificial Intelligence (AI) is the simulation of human intelligence by machines.\n",
    "AI systems can perform tasks that typically require human intelligence, such as\n",
    "visual perception, speech recognition, decision-making, and language translation.\n",
    "\n",
    "Types of AI:\n",
    "1. Narrow AI: Designed for specific tasks (e.g., image recognition)\n",
    "2. General AI: Theoretical AI with human-like intelligence\n",
    "3. Super AI: Hypothetical AI that surpasses human intelligence\n",
    "\n",
    "Machine Learning is a subset of AI that enables systems to learn from data.\n",
    "Deep Learning is a subset of Machine Learning using neural networks.\n",
    "\"\"\"\n",
    "\n",
    "# Save to file\n",
    "with open(\"sample_ai_doc.txt\", \"w\") as f:\n",
    "    f.write(sample_text)\n",
    "\n",
    "print(\"‚úÖ Sample document created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load text document\n",
    "loader = TextLoader(\"sample_ai_doc.txt\")\n",
    "documents = loader.load()\n",
    "\n",
    "print(f\"üìÑ Loaded {len(documents)} document(s)\")\n",
    "print(f\"\\nDocument content preview:\")\n",
    "print(documents[0].page_content[:200] + \"...\")\n",
    "print(f\"\\nMetadata: {documents[0].metadata}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3.2: Text Splitting Strategies\n",
    "\n",
    "### Why Split Text?\n",
    "\n",
    "1. **Token Limits:** LLMs have maximum context length\n",
    "2. **Relevance:** Smaller chunks = more precise retrieval\n",
    "3. **Performance:** Faster search with smaller chunks\n",
    "4. **Cost:** Only send relevant context to LLM\n",
    "\n",
    "### Key Parameters:\n",
    "\n",
    "- **chunk_size:** Target size of each chunk (in characters)\n",
    "- **chunk_overlap:** Overlap between chunks to preserve context\n",
    "- **separators:** How to split (by sentence, paragraph, etc.)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RecursiveCharacterTextSplitter\n",
    "\n",
    "Tries to split on different separators in order of preference:\n",
    "1. Double newlines (paragraphs)\n",
    "2. Single newlines (lines)\n",
    "3. Spaces (words)\n",
    "4. Characters (as last resort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create text splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=200,      # Target chunk size\n",
    "    chunk_overlap=50,    # Overlap between chunks\n",
    "    length_function=len,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    ")\n",
    "\n",
    "# Split the document\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "print(f\"üìÑ Original document split into {len(chunks)} chunks\\n\")\n",
    "\n",
    "for i, chunk in enumerate(chunks, 1):\n",
    "    print(f\"Chunk {i} (length: {len(chunk.page_content)}):\")\n",
    "    print(chunk.page_content)\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Different Chunk Sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different chunk sizes\n",
    "chunk_sizes = [100, 300, 500]\n",
    "\n",
    "for size in chunk_sizes:\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=size,\n",
    "        chunk_overlap=20\n",
    "    )\n",
    "    chunks = splitter.split_documents(documents)\n",
    "    print(f\"Chunk size {size}: {len(chunks)} chunks created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Custom Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add custom metadata to chunks\n",
    "for i, chunk in enumerate(chunks):\n",
    "    chunk.metadata[\"chunk_id\"] = i\n",
    "    chunk.metadata[\"chunk_size\"] = len(chunk.page_content)\n",
    "    chunk.metadata[\"document_name\"] = \"AI Introduction\"\n",
    "\n",
    "print(\"Enhanced metadata for first chunk:\")\n",
    "print(chunks[0].metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Section 4: Building RAG Applications (35 minutes)\n",
    "\n",
    "Now let's put it all together to build a complete RAG system!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1: Complete RAG Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load and split documents\n",
    "loader = TextLoader(\"sample_ai_doc.txt\")\n",
    "documents = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=300,\n",
    "    chunk_overlap=50\n",
    ")\n",
    "splits = text_splitter.split_documents(documents)\n",
    "\n",
    "print(f\"üìÑ Loaded and split into {len(splits)} chunks\")\n",
    "\n",
    "# Step 2: Create vector store\n",
    "vectorstore = PGVector.from_documents(\n",
    "    documents=splits,\n",
    "    embedding=embeddings,\n",
    "    collection_name=\"rag_demo\",\n",
    "    connection_string=CONNECTION_STRING,\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Vector store created\")\n",
    "\n",
    "# Step 3: Create retriever\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 3}  # Retrieve top 3 chunks\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Retriever configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2: Test Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the retriever\n",
    "query = \"What are the types of AI?\"\n",
    "retrieved_docs = retriever.get_relevant_documents(query)\n",
    "\n",
    "print(f\"üîç Query: {query}\")\n",
    "print(f\"\\nüìö Retrieved {len(retrieved_docs)} relevant chunks:\\n\")\n",
    "\n",
    "for i, doc in enumerate(retrieved_docs, 1):\n",
    "    print(f\"Chunk {i}:\")\n",
    "    print(textwrap.fill(doc.page_content, width=80))\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3: Build RAG Chain with LCEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LLM\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "# Create RAG prompt template\n",
    "rag_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "Answer the question based only on the following context:\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer: Provide a clear and concise answer based on the context above. \n",
    "If the answer cannot be found in the context, say \"I don't have enough information to answer that.\"\n",
    "\"\"\")\n",
    "\n",
    "# Helper function to format documents\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# Build the RAG chain using LCEL\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | rag_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(\"‚úÖ RAG chain created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4: Query the RAG System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask questions\n",
    "questions = [\n",
    "    \"What is Artificial Intelligence?\",\n",
    "    \"What are the three types of AI mentioned?\",\n",
    "    \"How is Machine Learning related to AI?\",\n",
    "    \"What is quantum computing?\"  # Not in the context\n",
    "]\n",
    "\n",
    "for question in questions:\n",
    "    print(f\"\\n‚ùì Question: {question}\")\n",
    "    answer = rag_chain.invoke(question)\n",
    "    print(f\"üí° Answer: {answer}\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5: RAG with Source Citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced RAG chain that returns sources\n",
    "def rag_with_sources(question: str):\n",
    "    \"\"\"RAG that returns answer with source documents.\"\"\"\n",
    "    \n",
    "    # Retrieve documents\n",
    "    docs = retriever.get_relevant_documents(question)\n",
    "    \n",
    "    # Format context\n",
    "    context = format_docs(docs)\n",
    "    \n",
    "    # Get answer\n",
    "    answer = rag_chain.invoke(question)\n",
    "    \n",
    "    return {\n",
    "        \"question\": question,\n",
    "        \"answer\": answer,\n",
    "        \"sources\": docs\n",
    "    }\n",
    "\n",
    "# Test with sources\n",
    "result = rag_with_sources(\"What is Deep Learning?\")\n",
    "\n",
    "print(f\"‚ùì Question: {result['question']}\")\n",
    "print(f\"\\nüí° Answer: {result['answer']}\")\n",
    "print(f\"\\nüìö Sources:\")\n",
    "for i, doc in enumerate(result['sources'], 1):\n",
    "    print(f\"\\n{i}. {doc.metadata.get('source', 'Unknown')}\")\n",
    "    print(f\"   {textwrap.fill(doc.page_content, width=70, initial_indent='   ', subsequent_indent='   ')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Section 5: Conversational RAG (15 minutes)\n",
    "\n",
    "Add memory to create a conversational RAG system that remembers context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1: RAG with Conversation History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "from langchain.chains import create_history_aware_retriever, create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "contextualize_q_system_prompt = \"\"\"Given a chat history and the latest user question \\\n",
    "which might reference context in the chat history, formulate a standalone question \\\n",
    "which can be understood without the chat history. Do NOT answer the question, \\\n",
    "just reformulate it if needed and otherwise return it as is.\"\"\"\n",
    "\n",
    "contextualize_q_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", contextualize_q_system_prompt),\n",
    "    MessagesPlaceholder(\"chat_history\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "])\n",
    "\n",
    "history_aware_retriever = create_history_aware_retriever(\n",
    "    llm, retriever, contextualize_q_prompt\n",
    ")\n",
    "\n",
    "qa_system_prompt = \"\"\"You are an assistant for question-answering tasks. \\\n",
    "Use the following pieces of retrieved context to answer the question. \\\n",
    "If you don't know the answer, just say that you don't know. \\\n",
    "Keep the answer concise.\n",
    "\n",
    "{context}\"\"\"\n",
    "\n",
    "qa_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", qa_system_prompt),\n",
    "    MessagesPlaceholder(\"chat_history\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "])\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)\n",
    "\n",
    "conversational_rag = create_retrieval_chain(\n",
    "    history_aware_retriever, question_answer_chain\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Conversational RAG chain created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2: Have a Conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_sequence = [\n",
    "    \"What is Artificial Intelligence?\",\n",
    "    \"Can you tell me about the types?\",\n",
    "    \"Which one is theoretical?\",\n",
    "    \"How does Machine Learning fit into this?\"\n",
    "]\n",
    "\n",
    "chat_history = []\n",
    "\n",
    "print(\"üó£Ô∏è Starting Conversation:\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for question in questions_sequence:\n",
    "    print(f\"\\nüë§ User: {question}\")\n",
    "    \n",
    "    result = conversational_rag.invoke({\n",
    "        \"input\": question,\n",
    "        \"chat_history\": chat_history\n",
    "    })\n",
    "    \n",
    "    chat_history.append(HumanMessage(content=question))\n",
    "    chat_history.append(AIMessage(content=result[\"answer\"]))\n",
    "    \n",
    "    print(f\"ü§ñ Assistant: {result['answer']}\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3: View Conversation History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìú Conversation History:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for message in chat_history:\n",
    "    role = \"üë§ User\" if isinstance(message, HumanMessage) else \"ü§ñ Assistant\"\n",
    "    print(f\"\\n{role}: {message.content}\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "print(f\"\\nTotal messages in history: {len(chat_history)}\")\n",
    "print(f\"Number of exchanges: {len(chat_history) // 2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# üéØ Summary & Key Takeaways\n",
    "\n",
    "## What We Learned:\n",
    "\n",
    "### 1. **RAG Fundamentals**\n",
    "- What RAG is and why it's powerful\n",
    "- How RAG solves LLM limitations\n",
    "- RAG architecture and workflow\n",
    "\n",
    "### 2. **Embeddings & Vectors**\n",
    "- Text embeddings capture semantic meaning\n",
    "- Vector similarity measures relatedness\n",
    "- OpenAI embeddings API usage\n",
    "\n",
    "### 3. **PGVector**\n",
    "- Setting up PostgreSQL with PGVector\n",
    "- Storing and searching vectors\n",
    "- Metadata filtering\n",
    "- Similarity search with scores\n",
    "\n",
    "### 4. **Document Processing**\n",
    "- Document loaders for different formats\n",
    "- Text splitting strategies\n",
    "- Chunk size and overlap considerations\n",
    "- Metadata management\n",
    "\n",
    "### 5. **Building RAG Applications**\n",
    "- Complete RAG pipeline with LCEL\n",
    "- Retriever configuration\n",
    "- Source citation\n",
    "- Conversational RAG with memory\n",
    "\n",
    "---\n",
    "\n",
    "## üìù Next Steps:\n",
    "\n",
    "### Exercises for This Week:\n",
    "\n",
    "**Exercise 1 (Due Monday):** `02_exercise_knowledge_base.ipynb`\n",
    "- Build personal knowledge base with RAG\n",
    "- Upload and process multiple documents\n",
    "- Implement Q&A with citations\n",
    "\n",
    "**Exercise 2 (Due Friday):** `03_exercise_research_assistant.ipynb`\n",
    "- Multi-document research assistant\n",
    "- Metadata filtering and organization\n",
    "- Advanced retrieval strategies\n",
    "\n",
    "---\n",
    "\n",
    "## ü§î Reflection Questions:\n",
    "\n",
    "1. When should you use RAG vs fine-tuning?\n",
    "2. How does chunk size affect retrieval quality?\n",
    "3. What are the trade-offs of different text splitting strategies?\n",
    "4. How can you improve RAG accuracy?\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Additional Resources:\n",
    "\n",
    "- [LangChain RAG Tutorial](https://python.langchain.com/docs/use_cases/question_answering/)\n",
    "- [PGVector Documentation](https://github.com/pgvector/pgvector)\n",
    "- [OpenAI Embeddings Guide](https://platform.openai.com/docs/guides/embeddings)\n",
    "\n",
    "---\n",
    "\n",
    "**Next Week:** Introduction to LangGraph! üöÄ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
