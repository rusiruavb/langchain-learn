{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Week 5: Advanced LangGraph - Multi-Agent Systems\n",
        "\n",
        "## üìö Session Overview\n",
        "\n",
        "**Duration:** 2 hours  \n",
        "**Week:** 5  \n",
        "**Instructor-Led Session**\n",
        "\n",
        "---\n",
        "\n",
        "## üéØ Learning Objectives\n",
        "\n",
        "By the end of this session, you will be able to:\n",
        "1. Build multi-agent systems with LangGraph\n",
        "2. Implement human-in-the-loop workflows\n",
        "3. Create sub-graphs and compose complex workflows\n",
        "4. Use tool calling within graphs\n",
        "5. Implement persistent state with checkpoints\n",
        "6. Handle errors and implement retry logic\n",
        "\n",
        "---\n",
        "\n",
        "## üìã Prerequisites\n",
        "\n",
        "- ‚úÖ Completed Week 1-4\n",
        "- ‚úÖ Strong understanding of LangGraph basics\n",
        "- ‚úÖ Comfortable with state management\n",
        "- ‚úÖ Understanding of conditional routing\n",
        "\n",
        "---\n",
        "\n",
        "## ‚è±Ô∏è Estimated Time\n",
        "\n",
        "- Setup & Review: 10 minutes\n",
        "- Section 1 (Multi-Agent Systems): 30 minutes\n",
        "- Section 2 (Human-in-the-Loop): 25 minutes\n",
        "- Section 3 (Tool Calling): 25 minutes\n",
        "- Section 4 (Advanced Patterns): 25 minutes\n",
        "- Wrap-up & Q&A: 5 minutes\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîß Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from typing import TypedDict, Annotated, Sequence, Literal\n",
        "import operator\n",
        "from datetime import datetime\n",
        "\n",
        "# LangChain imports\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage, BaseMessage\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_core.tools import tool\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "# LangGraph imports\n",
        "from langgraph.graph import StateGraph, END\n",
        "from langgraph.prebuilt import ToolNode\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv()\n",
        "\n",
        "# Initialize LLM\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.7)\n",
        "\n",
        "print(\"‚úÖ Setup complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Section 1: Multi-Agent Systems (30 minutes)\n",
        "\n",
        "## What are Multi-Agent Systems?\n",
        "\n",
        "**Multi-agent systems** use multiple specialized agents working together to solve complex problems.\n",
        "\n",
        "### Why Multi-Agent?\n",
        "\n",
        "**Single Agent Limitations:**\n",
        "- ‚ùå Jack of all trades, master of none\n",
        "- ‚ùå Complex system prompts\n",
        "- ‚ùå Hard to debug and maintain\n",
        "- ‚ùå Limited by single model's capabilities\n",
        "\n",
        "**Multi-Agent Benefits:**\n",
        "- ‚úÖ Specialized agents for specific tasks\n",
        "- ‚úÖ Modular and maintainable\n",
        "- ‚úÖ Easier to test individual agents\n",
        "- ‚úÖ Can use different models per agent\n",
        "- ‚úÖ Parallel execution where possible\n",
        "\n",
        "---\n",
        "\n",
        "## Common Multi-Agent Patterns\n",
        "\n",
        "### 1. **Sequential Handoff**\n",
        "```\n",
        "Agent A ‚Üí Agent B ‚Üí Agent C ‚Üí Result\n",
        "```\n",
        "Each agent passes work to the next specialist.\n",
        "\n",
        "### 2. **Supervisor Pattern**\n",
        "```\n",
        "          Supervisor\n",
        "         /     |     \\\n",
        "    Agent A  Agent B  Agent C\n",
        "```\n",
        "Supervisor routes tasks to appropriate workers.\n",
        "\n",
        "### 3. **Collaborative**\n",
        "```\n",
        "Agent A ‚Üê‚Üí Agent B ‚Üê‚Üí Agent C\n",
        "```\n",
        "Agents communicate back and forth.\n",
        "\n",
        "### 4. **Hierarchical**\n",
        "```\n",
        "     Manager Agent\n",
        "         |\n",
        "    Team Lead Agent\n",
        "      /        \\\n",
        "  Worker A   Worker B\n",
        "```\n",
        "Multiple levels of coordination.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.1: Building a Research Team (Supervisor Pattern)\n",
        "\n",
        "Let's build a research team with:\n",
        "- **Supervisor:** Routes tasks to specialists\n",
        "- **Researcher:** Gathers information\n",
        "- **Analyst:** Analyzes findings\n",
        "- **Writer:** Creates final report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define state for research team\n",
        "class ResearchState(TypedDict):\n",
        "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
        "    task: str\n",
        "    research_findings: str\n",
        "    analysis: str\n",
        "    final_report: str\n",
        "    next_agent: str\n",
        "\n",
        "print(\"‚úÖ Research state defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create specialized agents\n",
        "\n",
        "def supervisor(state: ResearchState) -> ResearchState:\n",
        "    \"\"\"\n",
        "    Supervisor decides which agent should act next.\n",
        "    \"\"\"\n",
        "    messages = state[\"messages\"]\n",
        "    \n",
        "    # Determine next step based on current state\n",
        "    if not state.get(\"research_findings\"):\n",
        "        next_agent = \"researcher\"\n",
        "    elif not state.get(\"analysis\"):\n",
        "        next_agent = \"analyst\"\n",
        "    elif not state.get(\"final_report\"):\n",
        "        next_agent = \"writer\"\n",
        "    else:\n",
        "        next_agent = \"FINISH\"\n",
        "    \n",
        "    print(f\"üëî Supervisor: Routing to {next_agent}\")\n",
        "    \n",
        "    return {\n",
        "        \"next_agent\": next_agent,\n",
        "        \"messages\": [SystemMessage(content=f\"Routing to {next_agent}\")]\n",
        "    }\n",
        "\n",
        "def researcher(state: ResearchState) -> ResearchState:\n",
        "    \"\"\"\n",
        "    Researcher gathers information on the task.\n",
        "    \"\"\"\n",
        "    task = state[\"task\"]\n",
        "    \n",
        "    prompt = ChatPromptTemplate.from_messages([\n",
        "        (\"system\", \"You are a thorough researcher. Gather key information about the topic.\"),\n",
        "        (\"human\", \"Research this topic: {task}\")\n",
        "    ])\n",
        "    \n",
        "    chain = prompt | llm | StrOutputParser()\n",
        "    findings = chain.invoke({\"task\": task})\n",
        "    \n",
        "    print(f\"üî¨ Researcher: Completed research\")\n",
        "    \n",
        "    return {\n",
        "        \"research_findings\": findings,\n",
        "        \"messages\": [AIMessage(content=f\"Research complete: {findings[:100]}...\")]\n",
        "    }\n",
        "\n",
        "def analyst(state: ResearchState) -> ResearchState:\n",
        "    \"\"\"\n",
        "    Analyst analyzes the research findings.\n",
        "    \"\"\"\n",
        "    findings = state[\"research_findings\"]\n",
        "    \n",
        "    prompt = ChatPromptTemplate.from_messages([\n",
        "        (\"system\", \"You are an analytical expert. Analyze the research and draw insights.\"),\n",
        "        (\"human\", \"Analyze these findings: {findings}\")\n",
        "    ])\n",
        "    \n",
        "    chain = prompt | llm | StrOutputParser()\n",
        "    analysis = chain.invoke({\"findings\": findings})\n",
        "    \n",
        "    print(f\"üìä Analyst: Completed analysis\")\n",
        "    \n",
        "    return {\n",
        "        \"analysis\": analysis,\n",
        "        \"messages\": [AIMessage(content=f\"Analysis complete: {analysis[:100]}...\")]\n",
        "    }\n",
        "\n",
        "def writer(state: ResearchState) -> ResearchState:\n",
        "    \"\"\"\n",
        "    Writer creates the final report.\n",
        "    \"\"\"\n",
        "    findings = state[\"research_findings\"]\n",
        "    analysis = state[\"analysis\"]\n",
        "    \n",
        "    prompt = ChatPromptTemplate.from_messages([\n",
        "        (\"system\", \"You are a skilled technical writer. Create a clear, concise report.\"),\n",
        "        (\"human\", \"Create a report based on:\\n\\nFindings: {findings}\\n\\nAnalysis: {analysis}\")\n",
        "    ])\n",
        "    \n",
        "    chain = prompt | llm | StrOutputParser()\n",
        "    report = chain.invoke({\"findings\": findings, \"analysis\": analysis})\n",
        "    \n",
        "    print(f\"‚úçÔ∏è Writer: Completed report\")\n",
        "    \n",
        "    return {\n",
        "        \"final_report\": report,\n",
        "        \"messages\": [AIMessage(content=f\"Report complete: {report[:100]}...\")]\n",
        "    }\n",
        "\n",
        "print(\"‚úÖ Agent functions created\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build the research team graph\n",
        "research_workflow = StateGraph(ResearchState)\n",
        "\n",
        "# Add agent nodes\n",
        "research_workflow.add_node(\"supervisor\", supervisor)\n",
        "research_workflow.add_node(\"researcher\", researcher)\n",
        "research_workflow.add_node(\"analyst\", analyst)\n",
        "research_workflow.add_node(\"writer\", writer)\n",
        "\n",
        "# Set entry point\n",
        "research_workflow.set_entry_point(\"supervisor\")\n",
        "\n",
        "# Define routing logic\n",
        "def route_to_agent(state: ResearchState) -> str:\n",
        "    \"\"\"Route to the next agent based on supervisor decision.\"\"\"\n",
        "    return state[\"next_agent\"]\n",
        "\n",
        "# Add conditional edges from supervisor\n",
        "research_workflow.add_conditional_edges(\n",
        "    \"supervisor\",\n",
        "    route_to_agent,\n",
        "    {\n",
        "        \"researcher\": \"researcher\",\n",
        "        \"analyst\": \"analyst\",\n",
        "        \"writer\": \"writer\",\n",
        "        \"FINISH\": END\n",
        "    }\n",
        ")\n",
        "\n",
        "# All agents return to supervisor\n",
        "research_workflow.add_edge(\"researcher\", \"supervisor\")\n",
        "research_workflow.add_edge(\"analyst\", \"supervisor\")\n",
        "research_workflow.add_edge(\"writer\", \"supervisor\")\n",
        "\n",
        "# Compile\n",
        "research_app = research_workflow.compile()\n",
        "\n",
        "print(\"‚úÖ Research team graph created\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test the research team\n",
        "initial_state = {\n",
        "    \"task\": \"The impact of artificial intelligence on healthcare\",\n",
        "    \"messages\": [],\n",
        "    \"research_findings\": \"\",\n",
        "    \"analysis\": \"\",\n",
        "    \"final_report\": \"\",\n",
        "    \"next_agent\": \"\"\n",
        "}\n",
        "\n",
        "print(\"üöÄ Starting research team workflow...\\n\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "result = research_app.invoke(initial_state)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"\\nüìÑ Final Report:\")\n",
        "print(result[\"final_report\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Section 2: Human-in-the-Loop (25 minutes)\n",
        "\n",
        "## What is Human-in-the-Loop?\n",
        "\n",
        "**Human-in-the-loop (HITL)** allows humans to interact with the graph during execution.\n",
        "\n",
        "### Use Cases:\n",
        "- ‚úÖ Approval workflows (content moderation, financial decisions)\n",
        "- ‚úÖ Quality control (review AI outputs before proceeding)\n",
        "- ‚úÖ Collaborative tasks (AI suggests, human decides)\n",
        "- ‚úÖ Sensitive operations (legal, medical, financial)\n",
        "- ‚úÖ Learning systems (human feedback improves AI)\n",
        "\n",
        "---\n",
        "\n",
        "## How HITL Works in LangGraph\n",
        "\n",
        "1. Graph pauses at specific nodes\n",
        "2. Waits for human input/approval\n",
        "3. Resumes with human feedback\n",
        "4. Continues to completion\n",
        "\n",
        "**Key Component:** Checkpointing (state persistence)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2.1: Content Approval Workflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define state for approval workflow\n",
        "class ApprovalState(TypedDict):\n",
        "    content: str\n",
        "    draft: str\n",
        "    feedback: str\n",
        "    approved: bool\n",
        "    revision_count: int\n",
        "\n",
        "# Generate content draft\n",
        "def generate_draft(state: ApprovalState) -> ApprovalState:\n",
        "    \"\"\"Generate initial content draft.\"\"\"\n",
        "    content_request = state[\"content\"]\n",
        "    feedback = state.get(\"feedback\", \"\")\n",
        "    revision = state.get(\"revision_count\", 0)\n",
        "    \n",
        "    if revision == 0:\n",
        "        prompt = f\"Create content about: {content_request}\"\n",
        "    else:\n",
        "        prompt = f\"Revise this content based on feedback.\\n\\nOriginal: {state.get('draft')}\\n\\nFeedback: {feedback}\"\n",
        "    \n",
        "    draft = llm.invoke(prompt).content\n",
        "    \n",
        "    print(f\"üìù Generated draft (revision {revision + 1})\")\n",
        "    print(f\"Draft preview: {draft[:100]}...\\n\")\n",
        "    \n",
        "    return {\n",
        "        \"draft\": draft,\n",
        "        \"revision_count\": revision + 1\n",
        "    }\n",
        "\n",
        "# Human review node\n",
        "def human_review(state: ApprovalState) -> ApprovalState:\n",
        "    \"\"\"\n",
        "    Wait for human approval.\n",
        "    This node will pause execution.\n",
        "    \"\"\"\n",
        "    print(\"‚è∏Ô∏è Paused for human review...\")\n",
        "    # In production, this would integrate with a review UI\n",
        "    # For demo, we'll simulate approval\n",
        "    return state\n",
        "\n",
        "# Check approval decision\n",
        "def check_approval(state: ApprovalState) -> str:\n",
        "    \"\"\"Route based on approval decision.\"\"\"\n",
        "    if state.get(\"approved\", False):\n",
        "        return \"approved\"\n",
        "    else:\n",
        "        return \"revise\"\n",
        "\n",
        "# Finalize\n",
        "def finalize(state: ApprovalState) -> ApprovalState:\n",
        "    \"\"\"Finalize approved content.\"\"\"\n",
        "    print(\"‚úÖ Content approved and finalized!\")\n",
        "    return state\n",
        "\n",
        "print(\"‚úÖ Approval workflow functions created\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build approval workflow with checkpointing\n",
        "memory = MemorySaver()\n",
        "\n",
        "approval_workflow = StateGraph(ApprovalState)\n",
        "\n",
        "# Add nodes\n",
        "approval_workflow.add_node(\"generate\", generate_draft)\n",
        "approval_workflow.add_node(\"review\", human_review)\n",
        "approval_workflow.add_node(\"finalize\", finalize)\n",
        "\n",
        "# Set entry\n",
        "approval_workflow.set_entry_point(\"generate\")\n",
        "\n",
        "# Add edges\n",
        "approval_workflow.add_edge(\"generate\", \"review\")\n",
        "\n",
        "# Conditional routing from review\n",
        "approval_workflow.add_conditional_edges(\n",
        "    \"review\",\n",
        "    check_approval,\n",
        "    {\n",
        "        \"approved\": \"finalize\",\n",
        "        \"revise\": \"generate\"  # Loop back\n",
        "    }\n",
        ")\n",
        "\n",
        "approval_workflow.add_edge(\"finalize\", END)\n",
        "\n",
        "# Compile with checkpointer (enables pausing/resuming)\n",
        "approval_app = approval_workflow.compile(\n",
        "    checkpointer=memory,\n",
        "    interrupt_before=[\"review\"]  # Pause before review node\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Approval workflow created with HITL\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Demonstrate HITL workflow\n",
        "config = {\"configurable\": {\"thread_id\": \"approval_1\"}}\n",
        "\n",
        "initial_state = {\n",
        "    \"content\": \"Write a blog post about Python programming best practices\",\n",
        "    \"draft\": \"\",\n",
        "    \"feedback\": \"\",\n",
        "    \"approved\": False,\n",
        "    \"revision_count\": 0\n",
        "}\n",
        "\n",
        "print(\"üöÄ Starting approval workflow...\\n\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Step 1: Generate draft (will pause at review)\n",
        "result = approval_app.invoke(initial_state, config=config)\n",
        "\n",
        "print(\"\\nüìã Current draft:\")\n",
        "print(result[\"draft\"][:200] + \"...\")\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "\n",
        "# Simulate human decision: Request revision\n",
        "print(\"\\nüë§ Human: Requesting revision - make it more beginner-friendly\")\n",
        "\n",
        "# Update state with feedback\n",
        "result[\"feedback\"] = \"Make this more beginner-friendly with simpler examples\"\n",
        "result[\"approved\"] = False\n",
        "\n",
        "# Step 2: Resume with feedback\n",
        "print(\"\\nüîÑ Resuming workflow with feedback...\\n\")\n",
        "result = approval_app.invoke(result, config=config)\n",
        "\n",
        "print(\"\\nüìã Revised draft:\")\n",
        "print(result[\"draft\"][:200] + \"...\")\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "\n",
        "# Simulate human approval\n",
        "print(\"\\nüë§ Human: Approving content\")\n",
        "result[\"approved\"] = True\n",
        "\n",
        "# Step 3: Finalize\n",
        "final_result = approval_app.invoke(result, config=config)\n",
        "\n",
        "print(f\"\\n‚úÖ Final revision count: {final_result['revision_count']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Section 3: Tool Calling in Graphs (25 minutes)\n",
        "\n",
        "## What is Tool Calling?\n",
        "\n",
        "**Tools** allow LLMs to interact with external systems:\n",
        "- Call APIs\n",
        "- Query databases\n",
        "- Perform calculations\n",
        "- Search the web\n",
        "- Execute code\n",
        "\n",
        "---\n",
        "\n",
        "## LangChain Tool Decorator\n",
        "\n",
        "Use `@tool` to create tools from Python functions:\n",
        "\n",
        "```python\n",
        "@tool\n",
        "def my_tool(param: str) -> str:\n",
        "    \"\"\"Tool description for the LLM.\"\"\"\n",
        "    return result\n",
        "```\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3.1: Create Custom Tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define custom tools\n",
        "@tool\n",
        "def calculate(expression: str) -> str:\n",
        "    \"\"\"Evaluate a mathematical expression safely.\"\"\"\n",
        "    try:\n",
        "        # Simple eval (in production, use safer alternatives)\n",
        "        result = eval(expression, {\"__builtins__\": {}}, {})\n",
        "        return f\"Result: {result}\"\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\"\n",
        "\n",
        "@tool\n",
        "def get_current_time() -> str:\n",
        "    \"\"\"Get the current date and time.\"\"\"\n",
        "    return datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "\n",
        "@tool\n",
        "def search_database(query: str) -> str:\n",
        "    \"\"\"Search a mock database for information.\"\"\"\n",
        "    # Mock database\n",
        "    database = {\n",
        "        \"python\": \"Python is a high-level programming language.\",\n",
        "        \"javascript\": \"JavaScript is a scripting language for web development.\",\n",
        "        \"ai\": \"Artificial Intelligence enables machines to simulate human intelligence.\"\n",
        "    }\n",
        "    \n",
        "    query_lower = query.lower()\n",
        "    for key, value in database.items():\n",
        "        if key in query_lower:\n",
        "            return value\n",
        "    \n",
        "    return \"No information found in database.\"\n",
        "\n",
        "# List of tools\n",
        "tools = [calculate, get_current_time, search_database]\n",
        "\n",
        "print(\"‚úÖ Tools created:\")\n",
        "for tool in tools:\n",
        "    print(f\"  - {tool.name}: {tool.description}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3.2: Build Agent with Tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_core.messages import ToolMessage\n",
        "\n",
        "# Define agent state\n",
        "class AgentState(TypedDict):\n",
        "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
        "\n",
        "# Bind tools to LLM\n",
        "llm_with_tools = llm.bind_tools(tools)\n",
        "\n",
        "# Agent node\n",
        "def agent(state: AgentState) -> AgentState:\n",
        "    \"\"\"\n",
        "    Agent decides whether to use tools or respond.\n",
        "    \"\"\"\n",
        "    messages = state[\"messages\"]\n",
        "    response = llm_with_tools.invoke(messages)\n",
        "    return {\"messages\": [response]}\n",
        "\n",
        "# Create tool node using LangGraph's prebuilt ToolNode\n",
        "tool_node = ToolNode(tools)\n",
        "\n",
        "# Routing function\n",
        "def should_continue(state: AgentState) -> Literal[\"tools\", \"end\"]:\n",
        "    \"\"\"\n",
        "    Determine if tools should be called or if we're done.\n",
        "    \"\"\"\n",
        "    messages = state[\"messages\"]\n",
        "    last_message = messages[-1]\n",
        "    \n",
        "    # If there are tool calls, route to tools\n",
        "    if hasattr(last_message, \"tool_calls\") and last_message.tool_calls:\n",
        "        return \"tools\"\n",
        "    # Otherwise, end\n",
        "    return \"end\"\n",
        "\n",
        "# Build graph\n",
        "tool_workflow = StateGraph(AgentState)\n",
        "\n",
        "# Add nodes\n",
        "tool_workflow.add_node(\"agent\", agent)\n",
        "tool_workflow.add_node(\"tools\", tool_node)\n",
        "\n",
        "# Set entry\n",
        "tool_workflow.set_entry_point(\"agent\")\n",
        "\n",
        "# Add conditional edges\n",
        "tool_workflow.add_conditional_edges(\n",
        "    \"agent\",\n",
        "    should_continue,\n",
        "    {\n",
        "        \"tools\": \"tools\",\n",
        "        \"end\": END\n",
        "    }\n",
        ")\n",
        "\n",
        "# Tools return to agent\n",
        "tool_workflow.add_edge(\"tools\", \"agent\")\n",
        "\n",
        "# Compile\n",
        "tool_app = tool_workflow.compile()\n",
        "\n",
        "print(\"‚úÖ Tool-calling agent created\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test tool-calling agent\n",
        "test_queries = [\n",
        "    \"What is 25 * 4 + 10?\",\n",
        "    \"What time is it right now?\",\n",
        "    \"Tell me about Python\"\n",
        "]\n",
        "\n",
        "for query in test_queries:\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"‚ùì Query: {query}\")\n",
        "    print()\n",
        "    \n",
        "    result = tool_app.invoke({\n",
        "        \"messages\": [HumanMessage(content=query)]\n",
        "    })\n",
        "    \n",
        "    # Get final response\n",
        "    final_message = result[\"messages\"][-1]\n",
        "    print(f\"üí° Response: {final_message.content}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Section 4: Advanced Patterns (25 minutes)\n",
        "\n",
        "## 4.1: Sub-Graphs (Graph Composition)\n",
        "\n",
        "**Sub-graphs** allow you to compose complex workflows from simpler graphs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define state for data processing pipeline\n",
        "class DataState(TypedDict):\n",
        "    raw_data: str\n",
        "    cleaned_data: str\n",
        "    processed_data: str\n",
        "    result: str\n",
        "\n",
        "# Sub-graph 1: Data Cleaning\n",
        "def clean_data(state: DataState) -> DataState:\n",
        "    \"\"\"Clean the raw data.\"\"\"\n",
        "    raw = state[\"raw_data\"]\n",
        "    cleaned = raw.strip().lower()\n",
        "    print(f\"üßπ Cleaned data: {cleaned}\")\n",
        "    return {\"cleaned_data\": cleaned}\n",
        "\n",
        "def validate_data(state: DataState) -> DataState:\n",
        "    \"\"\"Validate cleaned data.\"\"\"\n",
        "    cleaned = state[\"cleaned_data\"]\n",
        "    # Simple validation\n",
        "    if len(cleaned) > 0:\n",
        "        print(\"‚úÖ Data validated\")\n",
        "    return state\n",
        "\n",
        "# Create cleaning sub-graph\n",
        "cleaning_workflow = StateGraph(DataState)\n",
        "cleaning_workflow.add_node(\"clean\", clean_data)\n",
        "cleaning_workflow.add_node(\"validate\", validate_data)\n",
        "cleaning_workflow.set_entry_point(\"clean\")\n",
        "cleaning_workflow.add_edge(\"clean\", \"validate\")\n",
        "cleaning_workflow.add_edge(\"validate\", END)\n",
        "\n",
        "# Sub-graph 2: Data Processing\n",
        "def transform_data(state: DataState) -> DataState:\n",
        "    \"\"\"Transform the cleaned data.\"\"\"\n",
        "    cleaned = state[\"cleaned_data\"]\n",
        "    transformed = cleaned.upper()\n",
        "    print(f\"üîÑ Transformed data: {transformed}\")\n",
        "    return {\"processed_data\": transformed}\n",
        "\n",
        "def analyze_data(state: DataState) -> DataState:\n",
        "    \"\"\"Analyze processed data.\"\"\"\n",
        "    processed = state[\"processed_data\"]\n",
        "    result = f\"Analysis: {len(processed)} characters\"\n",
        "    print(f\"üìä {result}\")\n",
        "    return {\"result\": result}\n",
        "\n",
        "# Create processing sub-graph\n",
        "processing_workflow = StateGraph(DataState)\n",
        "processing_workflow.add_node(\"transform\", transform_data)\n",
        "processing_workflow.add_node(\"analyze\", analyze_data)\n",
        "processing_workflow.set_entry_point(\"transform\")\n",
        "processing_workflow.add_edge(\"transform\", \"analyze\")\n",
        "processing_workflow.add_edge(\"analyze\", END)\n",
        "\n",
        "# Main graph that uses sub-graphs\n",
        "main_workflow = StateGraph(DataState)\n",
        "\n",
        "# Add sub-graphs as nodes\n",
        "main_workflow.add_node(\"cleaning_pipeline\", cleaning_workflow.compile())\n",
        "main_workflow.add_node(\"processing_pipeline\", processing_workflow.compile())\n",
        "\n",
        "# Connect sub-graphs\n",
        "main_workflow.set_entry_point(\"cleaning_pipeline\")\n",
        "main_workflow.add_edge(\"cleaning_pipeline\", \"processing_pipeline\")\n",
        "main_workflow.add_edge(\"processing_pipeline\", END)\n",
        "\n",
        "# Compile main graph\n",
        "pipeline_app = main_workflow.compile()\n",
        "\n",
        "print(\"‚úÖ Composed pipeline with sub-graphs created\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test composed pipeline\n",
        "test_data = {\n",
        "    \"raw_data\": \"  Hello World  \",\n",
        "    \"cleaned_data\": \"\",\n",
        "    \"processed_data\": \"\",\n",
        "    \"result\": \"\"\n",
        "}\n",
        "\n",
        "print(\"üöÄ Running composed pipeline...\\n\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "result = pipeline_app.invoke(test_data)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(f\"\\nüìä Final Result: {result['result']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4.2: Error Handling and Retry Logic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define state with error tracking\n",
        "class RobustState(TypedDict):\n",
        "    task: str\n",
        "    result: str\n",
        "    error_count: int\n",
        "    max_retries: int\n",
        "    error_message: str\n",
        "\n",
        "# Simulated unreliable operation\n",
        "def unreliable_operation(state: RobustState) -> RobustState:\n",
        "    \"\"\"\n",
        "    Operation that might fail.\n",
        "    \"\"\"\n",
        "    import random\n",
        "    \n",
        "    error_count = state.get(\"error_count\", 0)\n",
        "    \n",
        "    # Simulate 50% failure rate\n",
        "    if random.random() < 0.5 and error_count < 2:\n",
        "        error_count += 1\n",
        "        print(f\"‚ùå Operation failed (attempt {error_count})\")\n",
        "        return {\n",
        "            \"error_count\": error_count,\n",
        "            \"error_message\": \"Random failure occurred\"\n",
        "        }\n",
        "    else:\n",
        "        print(\"‚úÖ Operation succeeded\")\n",
        "        return {\n",
        "            \"result\": f\"Completed: {state['task']}\",\n",
        "            \"error_message\": \"\"\n",
        "        }\n",
        "\n",
        "# Check if should retry\n",
        "def should_retry(state: RobustState) -> str:\n",
        "    \"\"\"Decide whether to retry or finish.\"\"\"\n",
        "    if state.get(\"result\"):\n",
        "        return \"success\"\n",
        "    elif state.get(\"error_count\", 0) >= state.get(\"max_retries\", 3):\n",
        "        return \"max_retries\"\n",
        "    else:\n",
        "        return \"retry\"\n",
        "\n",
        "# Handle max retries\n",
        "def handle_failure(state: RobustState) -> RobustState:\n",
        "    \"\"\"Handle permanent failure.\"\"\"\n",
        "    print(\"‚ö†Ô∏è Max retries exceeded\")\n",
        "    return {\n",
        "        \"result\": f\"Failed after {state['error_count']} attempts\"\n",
        "    }\n",
        "\n",
        "# Build retry workflow\n",
        "retry_workflow = StateGraph(RobustState)\n",
        "\n",
        "# Add nodes\n",
        "retry_workflow.add_node(\"operation\", unreliable_operation)\n",
        "retry_workflow.add_node(\"handle_failure\", handle_failure)\n",
        "\n",
        "# Set entry\n",
        "retry_workflow.set_entry_point(\"operation\")\n",
        "\n",
        "# Add conditional edges\n",
        "retry_workflow.add_conditional_edges(\n",
        "    \"operation\",\n",
        "    should_retry,\n",
        "    {\n",
        "        \"success\": END,\n",
        "        \"retry\": \"operation\",  # Loop back\n",
        "        \"max_retries\": \"handle_failure\"\n",
        "    }\n",
        ")\n",
        "\n",
        "retry_workflow.add_edge(\"handle_failure\", END)\n",
        "\n",
        "# Compile\n",
        "retry_app = retry_workflow.compile()\n",
        "\n",
        "print(\"‚úÖ Retry workflow created\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test retry logic\n",
        "test_state = {\n",
        "    \"task\": \"Process important data\",\n",
        "    \"result\": \"\",\n",
        "    \"error_count\": 0,\n",
        "    \"max_retries\": 3,\n",
        "    \"error_message\": \"\"\n",
        "}\n",
        "\n",
        "print(\"üöÄ Testing retry logic...\\n\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "result = retry_app.invoke(test_state)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(f\"\\nüìä Result: {result['result']}\")\n",
        "print(f\"Retry count: {result.get('error_count', 0)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# üéØ Summary & Key Takeaways\n",
        "\n",
        "## What We Learned:\n",
        "\n",
        "### 1. **Multi-Agent Systems**\n",
        "- Supervisor pattern for coordinating specialists\n",
        "- Sequential handoff between agents\n",
        "- Benefits of specialized agents\n",
        "\n",
        "### 2. **Human-in-the-Loop**\n",
        "- Pausing execution with `interrupt_before`\n",
        "- Using checkpointers for state persistence\n",
        "- Resuming workflows with human feedback\n",
        "- Approval and review workflows\n",
        "\n",
        "### 3. **Tool Calling**\n",
        "- Creating tools with `@tool` decorator\n",
        "- Binding tools to LLMs\n",
        "- Using ToolNode for execution\n",
        "- Conditional routing with tool calls\n",
        "\n",
        "### 4. **Advanced Patterns**\n",
        "- Sub-graphs for modular workflows\n",
        "- Error handling and retry logic\n",
        "- Complex state management\n",
        "- Graph composition\n",
        "\n",
        "---\n",
        "\n",
        "## üìù Next Steps:\n",
        "\n",
        "### Exercises for This Week:\n",
        "\n",
        "**Exercise 1 (Due Monday):** `02_exercise_customer_service_team.ipynb`\n",
        "- Build multi-agent customer service system\n",
        "- Implement supervisor pattern\n",
        "- Add human escalation\n",
        "\n",
        "**Exercise 2 (Due Friday):** `03_exercise_research_agent.ipynb`\n",
        "- Create research agent with tools\n",
        "- Implement web search and analysis\n",
        "- Add quality checks and iterations\n",
        "\n",
        "---\n",
        "\n",
        "## ü§î Reflection Questions:\n",
        "\n",
        "1. When should you use multi-agent vs single agent?\n",
        "2. What are the trade-offs of human-in-the-loop?\n",
        "3. How do tools extend LLM capabilities?\n",
        "4. When is sub-graph composition useful?\n",
        "\n",
        "---\n",
        "\n",
        "## üìö Additional Resources:\n",
        "\n",
        "- [LangGraph Multi-Agent Tutorial](https://langchain-ai.github.io/langgraph/tutorials/multi_agent/)\n",
        "- [Human-in-the-Loop Guide](https://langchain-ai.github.io/langgraph/how-tos/human_in_the_loop/)\n",
        "- [Tool Calling Documentation](https://python.langchain.com/docs/modules/agents/tools/)\n",
        "\n",
        "---\n",
        "\n",
        "**Next Week:** Final Project - Build Your Own AI Agent! üöÄ"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
