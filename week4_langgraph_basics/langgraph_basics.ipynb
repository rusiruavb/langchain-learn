{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Week 4: Introduction to LangGraph\n",
        "\n",
        "## üìö Session Overview\n",
        "\n",
        "**Duration:** 2 hours  \n",
        "**Week:** 4  \n",
        "**Instructor-Led Session**\n",
        "\n",
        "---\n",
        "\n",
        "## üéØ Learning Objectives\n",
        "\n",
        "By the end of this session, you will be able to:\n",
        "1. Understand what LangGraph is and when to use it\n",
        "2. Create nodes, edges, and state in graphs\n",
        "3. Implement conditional routing logic\n",
        "4. Build stateful, cyclical workflows\n",
        "5. Visualize and debug graph execution\n",
        "6. Create practical multi-step agents\n",
        "\n",
        "---\n",
        "\n",
        "## üìã Prerequisites\n",
        "\n",
        "- ‚úÖ Completed Week 1, 2, and 3\n",
        "- ‚úÖ Strong understanding of LangChain chains\n",
        "- ‚úÖ Familiarity with LCEL\n",
        "- ‚úÖ Understanding of state management\n",
        "\n",
        "---\n",
        "\n",
        "## ‚è±Ô∏è Estimated Time\n",
        "\n",
        "- Setup & Introduction: 10 minutes\n",
        "- Section 1 (Why LangGraph): 20 minutes\n",
        "- Section 2 (Core Concepts): 30 minutes\n",
        "- Section 3 (Building Graphs): 35 minutes\n",
        "- Section 4 (Conditional Logic): 20 minutes\n",
        "- Wrap-up & Q&A: 5 minutes\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîß Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from typing import TypedDict, Annotated, Sequence\n",
        "import operator\n",
        "\n",
        "# LangChain imports\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.messages import HumanMessage, AIMessage, BaseMessage\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "# LangGraph imports\n",
        "from langgraph.graph import StateGraph, END\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv()\n",
        "\n",
        "# Initialize LLM\n",
        "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.7)\n",
        "\n",
        "print(\"‚úÖ Setup complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Section 1: Why LangGraph? (20 minutes)\n",
        "\n",
        "## The Problem with Chains\n",
        "\n",
        "**LangChain Chains** (LCEL) are great for **linear workflows**:\n",
        "\n",
        "```\n",
        "Input ‚Üí Step 1 ‚Üí Step 2 ‚Üí Step 3 ‚Üí Output\n",
        "```\n",
        "\n",
        "But they have limitations:\n",
        "\n",
        "### ‚ùå What Chains Can't Do Well:\n",
        "\n",
        "1. **Cycles/Loops:** Can't easily go back to previous steps\n",
        "2. **Complex Branching:** Limited conditional logic\n",
        "3. **Stateful Logic:** Hard to maintain complex state across steps\n",
        "4. **Dynamic Paths:** Can't decide flow based on intermediate results\n",
        "5. **Human-in-the-Loop:** No natural place to pause for input\n",
        "\n",
        "---\n",
        "\n",
        "## What is LangGraph?\n",
        "\n",
        "**LangGraph** is a library for building **stateful, multi-actor applications** with LLMs.\n",
        "\n",
        "### ‚úÖ What LangGraph Enables:\n",
        "\n",
        "1. **Cycles:** Loops and iterative refinement\n",
        "2. **Conditional Edges:** Dynamic routing based on state\n",
        "3. **Persistence:** Save and resume execution\n",
        "4. **Parallel Execution:** Run multiple nodes simultaneously\n",
        "5. **Human-in-the-Loop:** Pause for human approval/input\n",
        "6. **Complex State:** Track multiple pieces of information\n",
        "\n",
        "---\n",
        "\n",
        "## When to Use LangGraph vs Chains\n",
        "\n",
        "### Use **Chains** when:\n",
        "- Linear workflow (A ‚Üí B ‚Üí C)\n",
        "- No loops or cycles needed\n",
        "- Simple conditional logic\n",
        "- Single pass through data\n",
        "\n",
        "**Examples:**\n",
        "- Translate text\n",
        "- Summarize document\n",
        "- Simple Q&A\n",
        "- Data transformation pipeline\n",
        "\n",
        "### Use **LangGraph** when:\n",
        "- Need cycles/loops\n",
        "- Complex decision trees\n",
        "- Multiple agents/actors\n",
        "- Iterative refinement\n",
        "- Human approval needed\n",
        "- Long-running workflows\n",
        "\n",
        "**Examples:**\n",
        "- Research agent (search ‚Üí analyze ‚Üí search more)\n",
        "- Code reviewer (review ‚Üí fix ‚Üí review again)\n",
        "- Customer support router (classify ‚Üí route ‚Üí escalate)\n",
        "- Content moderation (check ‚Üí human review ‚Üí approve)\n",
        "\n",
        "---\n",
        "\n",
        "## Real-World Example\n",
        "\n",
        "**Scenario:** Content Generation with Quality Control\n",
        "\n",
        "**With Chains (Linear):**\n",
        "```\n",
        "Generate Draft ‚Üí Polish ‚Üí Done\n",
        "```\n",
        "‚ùå Problem: Can't iterate if quality is low\n",
        "\n",
        "**With LangGraph (Cyclical):**\n",
        "```\n",
        "Generate Draft ‚Üí Check Quality\n",
        "                      ‚Üì\n",
        "           Good? ‚Üí Yes ‚Üí Done\n",
        "              ‚Üì\n",
        "             No ‚Üí Improve Draft (loop back)\n",
        "```\n",
        "‚úÖ Solution: Iterates until quality threshold met\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Section 2: LangGraph Core Concepts (30 minutes)\n",
        "\n",
        "LangGraph has three main building blocks:\n",
        "1. **State** - Data that flows through the graph\n",
        "2. **Nodes** - Functions that process state\n",
        "3. **Edges** - Connections between nodes\n",
        "\n",
        "---\n",
        "\n",
        "## 2.1: State - The Shared Memory\n",
        "\n",
        "**State** is a shared data structure that flows through the graph.\n",
        "\n",
        "### Defining State with TypedDict\n",
        "\n",
        "State is defined using Python's `TypedDict`:\n",
        "\n",
        "```python\n",
        "class MyState(TypedDict):\n",
        "    messages: list[str]      # List of messages\n",
        "    count: int               # A counter\n",
        "    user_name: str          # User's name\n",
        "```\n",
        "\n",
        "### State Reducers\n",
        "\n",
        "Sometimes you want to **combine** values instead of **replacing** them.\n",
        "\n",
        "**Without Reducer (Default - Replace):**\n",
        "```python\n",
        "class State(TypedDict):\n",
        "    messages: list  # Each node replaces the entire list\n",
        "```\n",
        "\n",
        "**With Reducer (Combine):**\n",
        "```python\n",
        "class State(TypedDict):\n",
        "    messages: Annotated[list, operator.add]  # Each node adds to the list\n",
        "```\n",
        "\n",
        "Common reducers:\n",
        "- `operator.add` - Concatenate lists/strings\n",
        "- Custom function - Your own logic\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example: Define a simple state\n",
        "class SimpleState(TypedDict):\n",
        "    input: str\n",
        "    output: str\n",
        "    step_count: int\n",
        "\n",
        "# Example: State with reducer\n",
        "class MessagesState(TypedDict):\n",
        "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
        "    current_step: str\n",
        "\n",
        "print(\"‚úÖ State schemas defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2.2: Nodes - Processing Functions\n",
        "\n",
        "**Nodes** are Python functions that:\n",
        "1. Receive the current state\n",
        "2. Process/transform it\n",
        "3. Return updates to the state\n",
        "\n",
        "### Node Function Signature\n",
        "\n",
        "```python\n",
        "def my_node(state: MyState) -> MyState:\n",
        "    \"\"\"Process the state and return updates.\"\"\"\n",
        "    # Read from state\n",
        "    current_value = state[\"some_key\"]\n",
        "    \n",
        "    # Do some processing\n",
        "    new_value = process(current_value)\n",
        "    \n",
        "    # Return state updates (partial update, not full state)\n",
        "    return {\"some_key\": new_value}\n",
        "```\n",
        "\n",
        "### Key Points:\n",
        "- Nodes are **pure functions** (no side effects when possible)\n",
        "- They receive the **full state**\n",
        "- They return **partial updates** (only changed fields)\n",
        "- LangGraph merges the updates into the state\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example nodes\n",
        "def node_a(state: SimpleState) -> SimpleState:\n",
        "    \"\"\"First processing step.\"\"\"\n",
        "    print(f\"Node A: Processing '{state['input']}'\")\n",
        "    return {\n",
        "        \"output\": f\"Processed by A: {state['input']}\",\n",
        "        \"step_count\": state.get(\"step_count\", 0) + 1\n",
        "    }\n",
        "\n",
        "def node_b(state: SimpleState) -> SimpleState:\n",
        "    \"\"\"Second processing step.\"\"\"\n",
        "    print(f\"Node B: Further processing '{state['output']}'\")\n",
        "    return {\n",
        "        \"output\": f\"Processed by B: {state['output']}\",\n",
        "        \"step_count\": state.get(\"step_count\", 0) + 1\n",
        "    }\n",
        "\n",
        "print(\"‚úÖ Node functions defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2.3: Edges - Connecting Nodes\n",
        "\n",
        "**Edges** define how nodes are connected.\n",
        "\n",
        "### Types of Edges:\n",
        "\n",
        "#### 1. **Normal Edges** (Direct connections)\n",
        "```python\n",
        "graph.add_edge(\"node_a\", \"node_b\")  # Always go from A to B\n",
        "```\n",
        "\n",
        "#### 2. **Conditional Edges** (Dynamic routing)\n",
        "```python\n",
        "def route_logic(state):\n",
        "    if state[\"score\"] > 0.8:\n",
        "        return \"approve\"\n",
        "    else:\n",
        "        return \"reject\"\n",
        "\n",
        "graph.add_conditional_edges(\n",
        "    \"check_quality\",\n",
        "    route_logic,\n",
        "    {\n",
        "        \"approve\": \"finalize\",\n",
        "        \"reject\": \"improve\"\n",
        "    }\n",
        ")\n",
        "```\n",
        "\n",
        "#### 3. **Entry Point**\n",
        "```python\n",
        "graph.set_entry_point(\"start_node\")  # Where execution begins\n",
        "```\n",
        "\n",
        "#### 4. **END**\n",
        "```python\n",
        "from langgraph.graph import END\n",
        "graph.add_edge(\"final_node\", END)  # Terminates execution\n",
        "```\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Section 3: Building Your First Graph (35 minutes)\n",
        "\n",
        "Let's build a complete graph step by step."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3.1: Simple Linear Graph\n",
        "\n",
        "Start with a simple graph: A ‚Üí B ‚Üí C"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define state\n",
        "class LinearState(TypedDict):\n",
        "    text: str\n",
        "    steps: Annotated[list[str], operator.add]\n",
        "\n",
        "# Define nodes\n",
        "def step_1(state: LinearState) -> LinearState:\n",
        "    \"\"\"First step: capitalize.\"\"\"\n",
        "    return {\n",
        "        \"text\": state[\"text\"].upper(),\n",
        "        \"steps\": [\"Step 1: Capitalized\"]\n",
        "    }\n",
        "\n",
        "def step_2(state: LinearState) -> LinearState:\n",
        "    \"\"\"Second step: add prefix.\"\"\"\n",
        "    return {\n",
        "        \"text\": f\"PROCESSED: {state['text']}\",\n",
        "        \"steps\": [\"Step 2: Added prefix\"]\n",
        "    }\n",
        "\n",
        "def step_3(state: LinearState) -> LinearState:\n",
        "    \"\"\"Third step: add suffix.\"\"\"\n",
        "    return {\n",
        "        \"text\": f\"{state['text']} [DONE]\",\n",
        "        \"steps\": [\"Step 3: Added suffix\"]\n",
        "    }\n",
        "\n",
        "# Create the graph\n",
        "workflow = StateGraph(LinearState)\n",
        "\n",
        "# Add nodes\n",
        "workflow.add_node(\"step_1\", step_1)\n",
        "workflow.add_node(\"step_2\", step_2)\n",
        "workflow.add_node(\"step_3\", step_3)\n",
        "\n",
        "# Add edges (linear flow)\n",
        "workflow.set_entry_point(\"step_1\")\n",
        "workflow.add_edge(\"step_1\", \"step_2\")\n",
        "workflow.add_edge(\"step_2\", \"step_3\")\n",
        "workflow.add_edge(\"step_3\", END)\n",
        "\n",
        "# Compile the graph\n",
        "app = workflow.compile()\n",
        "\n",
        "print(\"‚úÖ Linear graph created\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Execute the graph\n",
        "initial_state = {\n",
        "    \"text\": \"hello world\",\n",
        "    \"steps\": []\n",
        "}\n",
        "\n",
        "result = app.invoke(initial_state)\n",
        "\n",
        "print(\"üìä Execution Result:\")\n",
        "print(f\"Final Text: {result['text']}\")\n",
        "print(f\"\\nSteps Executed:\")\n",
        "for step in result['steps']:\n",
        "    print(f\"  - {step}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3.2: Graph with Conditional Routing\n",
        "\n",
        "Let's add decision-making to the graph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define state for routing example\n",
        "class RoutingState(TypedDict):\n",
        "    message: str\n",
        "    category: str\n",
        "    response: str\n",
        "\n",
        "# Classifier node\n",
        "def classify_message(state: RoutingState) -> RoutingState:\n",
        "    \"\"\"Classify the incoming message.\"\"\"\n",
        "    message = state[\"message\"].lower()\n",
        "    \n",
        "    if \"urgent\" in message or \"asap\" in message:\n",
        "        category = \"urgent\"\n",
        "    elif \"question\" in message or \"how\" in message or \"what\" in message:\n",
        "        category = \"question\"\n",
        "    else:\n",
        "        category = \"general\"\n",
        "    \n",
        "    print(f\"üìã Classified as: {category}\")\n",
        "    return {\"category\": category}\n",
        "\n",
        "# Handler nodes\n",
        "def handle_urgent(state: RoutingState) -> RoutingState:\n",
        "    \"\"\"Handle urgent messages.\"\"\"\n",
        "    print(\"üö® Handling urgent message\")\n",
        "    return {\"response\": \"This has been escalated to priority support.\"}\n",
        "\n",
        "def handle_question(state: RoutingState) -> RoutingState:\n",
        "    \"\"\"Handle questions.\"\"\"\n",
        "    print(\"‚ùì Handling question\")\n",
        "    return {\"response\": \"Let me find the answer for you.\"}\n",
        "\n",
        "def handle_general(state: RoutingState) -> RoutingState:\n",
        "    \"\"\"Handle general messages.\"\"\"\n",
        "    print(\"üí¨ Handling general message\")\n",
        "    return {\"response\": \"Thank you for your message.\"}\n",
        "\n",
        "# Routing function\n",
        "def route_by_category(state: RoutingState) -> str:\n",
        "    \"\"\"Decide which node to route to based on category.\"\"\"\n",
        "    return state[\"category\"]\n",
        "\n",
        "# Create graph\n",
        "routing_workflow = StateGraph(RoutingState)\n",
        "\n",
        "# Add nodes\n",
        "routing_workflow.add_node(\"classify\", classify_message)\n",
        "routing_workflow.add_node(\"urgent\", handle_urgent)\n",
        "routing_workflow.add_node(\"question\", handle_question)\n",
        "routing_workflow.add_node(\"general\", handle_general)\n",
        "\n",
        "# Set entry point\n",
        "routing_workflow.set_entry_point(\"classify\")\n",
        "\n",
        "# Add conditional edges\n",
        "routing_workflow.add_conditional_edges(\n",
        "    \"classify\",\n",
        "    route_by_category,\n",
        "    {\n",
        "        \"urgent\": \"urgent\",\n",
        "        \"question\": \"question\",\n",
        "        \"general\": \"general\"\n",
        "    }\n",
        ")\n",
        "\n",
        "# All handlers go to END\n",
        "routing_workflow.add_edge(\"urgent\", END)\n",
        "routing_workflow.add_edge(\"question\", END)\n",
        "routing_workflow.add_edge(\"general\", END)\n",
        "\n",
        "# Compile\n",
        "routing_app = routing_workflow.compile()\n",
        "\n",
        "print(\"‚úÖ Routing graph created\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test the routing graph\n",
        "test_messages = [\n",
        "    \"URGENT: Server is down!\",\n",
        "    \"What is your return policy?\",\n",
        "    \"Thank you for the great service\"\n",
        "]\n",
        "\n",
        "for msg in test_messages:\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"üì® Message: {msg}\")\n",
        "    result = routing_app.invoke({\"message\": msg, \"category\": \"\", \"response\": \"\"})\n",
        "    print(f\"‚úÖ Response: {result['response']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3.3: Graph with Loops (Iterative Refinement)\n",
        "\n",
        "Build a graph that loops until a condition is met."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define state for iterative task\n",
        "class IterativeState(TypedDict):\n",
        "    draft: str\n",
        "    quality_score: float\n",
        "    iteration: int\n",
        "    max_iterations: int\n",
        "\n",
        "# Generate draft\n",
        "def generate_draft(state: IterativeState) -> IterativeState:\n",
        "    \"\"\"Generate or improve the draft.\"\"\"\n",
        "    iteration = state.get(\"iteration\", 0) + 1\n",
        "    \n",
        "    if iteration == 1:\n",
        "        draft = \"This is a basic draft.\"\n",
        "        print(f\"üìù Generated initial draft (iteration {iteration})\")\n",
        "    else:\n",
        "        draft = state[\"draft\"] + \" Enhanced with more detail.\"\n",
        "        print(f\"‚úèÔ∏è Improved draft (iteration {iteration})\")\n",
        "    \n",
        "    return {\n",
        "        \"draft\": draft,\n",
        "        \"iteration\": iteration\n",
        "    }\n",
        "\n",
        "# Evaluate quality\n",
        "def evaluate_quality(state: IterativeState) -> IterativeState:\n",
        "    \"\"\"Evaluate the quality of the draft.\"\"\"\n",
        "    # Simple quality scoring based on length\n",
        "    score = min(len(state[\"draft\"]) / 100, 1.0)\n",
        "    print(f\"üìä Quality score: {score:.2f}\")\n",
        "    return {\"quality_score\": score}\n",
        "\n",
        "# Routing logic\n",
        "def should_continue(state: IterativeState) -> str:\n",
        "    \"\"\"Decide whether to continue improving or finish.\"\"\"\n",
        "    if state[\"quality_score\"] >= 0.7:\n",
        "        print(\"‚úÖ Quality threshold met!\")\n",
        "        return \"finish\"\n",
        "    elif state[\"iteration\"] >= state[\"max_iterations\"]:\n",
        "        print(\"‚ö†Ô∏è Max iterations reached\")\n",
        "        return \"finish\"\n",
        "    else:\n",
        "        print(\"üîÑ Continuing to improve...\")\n",
        "        return \"continue\"\n",
        "\n",
        "# Create iterative graph\n",
        "iterative_workflow = StateGraph(IterativeState)\n",
        "\n",
        "# Add nodes\n",
        "iterative_workflow.add_node(\"generate\", generate_draft)\n",
        "iterative_workflow.add_node(\"evaluate\", evaluate_quality)\n",
        "\n",
        "# Set entry point\n",
        "iterative_workflow.set_entry_point(\"generate\")\n",
        "\n",
        "# Add edges\n",
        "iterative_workflow.add_edge(\"generate\", \"evaluate\")\n",
        "\n",
        "# Add conditional edge with loop\n",
        "iterative_workflow.add_conditional_edges(\n",
        "    \"evaluate\",\n",
        "    should_continue,\n",
        "    {\n",
        "        \"continue\": \"generate\",  # Loop back!\n",
        "        \"finish\": END\n",
        "    }\n",
        ")\n",
        "\n",
        "# Compile\n",
        "iterative_app = iterative_workflow.compile()\n",
        "\n",
        "print(\"‚úÖ Iterative graph created\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Execute iterative graph\n",
        "initial_state = {\n",
        "    \"draft\": \"\",\n",
        "    \"quality_score\": 0.0,\n",
        "    \"iteration\": 0,\n",
        "    \"max_iterations\": 5\n",
        "}\n",
        "\n",
        "print(\"üöÄ Starting iterative improvement...\\n\")\n",
        "result = iterative_app.invoke(initial_state)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üìä Final Result:\")\n",
        "print(f\"Iterations: {result['iteration']}\")\n",
        "print(f\"Quality Score: {result['quality_score']:.2f}\")\n",
        "print(f\"Final Draft: {result['draft']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Section 4: Advanced Graph Features (20 minutes)\n",
        "\n",
        "## 4.1: Graph Visualization\n",
        "\n",
        "LangGraph can generate visual representations of your graphs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get Mermaid diagram\n",
        "try:\n",
        "    from IPython.display import Image, display\n",
        "    \n",
        "    # Generate graph visualization\n",
        "    display(Image(routing_app.get_graph().draw_mermaid_png()))\n",
        "except Exception as e:\n",
        "    # If visualization fails, show text representation\n",
        "    print(\"Graph structure (Mermaid):\")\n",
        "    print(routing_app.get_graph().draw_mermaid())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4.2: Streaming Graph Execution\n",
        "\n",
        "Stream updates as the graph executes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Stream execution\n",
        "print(\"üîÑ Streaming graph execution:\\n\")\n",
        "\n",
        "initial_state = {\"message\": \"How do I reset my password?\", \"category\": \"\", \"response\": \"\"}\n",
        "\n",
        "for event in routing_app.stream(initial_state):\n",
        "    for node_name, node_output in event.items():\n",
        "        print(f\"üìç Node '{node_name}':\")\n",
        "        print(f\"   Output: {node_output}\")\n",
        "        print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4.3: Checkpointing (State Persistence)\n",
        "\n",
        "Save graph state and resume later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create graph with checkpointing\n",
        "memory = MemorySaver()\n",
        "\n",
        "# Recompile with checkpointer\n",
        "checkpointed_app = iterative_workflow.compile(checkpointer=memory)\n",
        "\n",
        "# Configuration for thread\n",
        "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
        "\n",
        "# Run with checkpointing\n",
        "initial_state = {\n",
        "    \"draft\": \"\",\n",
        "    \"quality_score\": 0.0,\n",
        "    \"iteration\": 0,\n",
        "    \"max_iterations\": 3\n",
        "}\n",
        "\n",
        "result = checkpointed_app.invoke(initial_state, config=config)\n",
        "\n",
        "print(\"‚úÖ Graph executed with checkpointing\")\n",
        "print(f\"Final iteration: {result['iteration']}\")\n",
        "\n",
        "# Get checkpoint history\n",
        "print(\"\\nüìú Checkpoint History:\")\n",
        "for state in checkpointed_app.get_state_history(config):\n",
        "    print(f\"  Iteration {state.values.get('iteration', 0)}: Score {state.values.get('quality_score', 0):.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4.4: Practical Example - Customer Support Router\n",
        "\n",
        "Complete example with LLM integration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# State for customer support\n",
        "class SupportState(TypedDict):\n",
        "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
        "    query: str\n",
        "    intent: str\n",
        "    response: str\n",
        "\n",
        "# Classify intent with LLM\n",
        "def classify_intent(state: SupportState) -> SupportState:\n",
        "    \"\"\"Use LLM to classify user intent.\"\"\"\n",
        "    prompt = ChatPromptTemplate.from_messages([\n",
        "        (\"system\", \"Classify the user query into one of: technical, billing, general. Respond with only one word.\"),\n",
        "        (\"human\", \"{query}\")\n",
        "    ])\n",
        "    \n",
        "    chain = prompt | llm\n",
        "    result = chain.invoke({\"query\": state[\"query\"]})\n",
        "    intent = result.content.strip().lower()\n",
        "    \n",
        "    print(f\"ü§ñ Classified intent: {intent}\")\n",
        "    \n",
        "    return {\n",
        "        \"intent\": intent,\n",
        "        \"messages\": [AIMessage(content=f\"Classified as {intent}\")]\n",
        "    }\n",
        "\n",
        "# Technical support\n",
        "def technical_support(state: SupportState) -> SupportState:\n",
        "    \"\"\"Handle technical queries.\"\"\"\n",
        "    prompt = ChatPromptTemplate.from_messages([\n",
        "        (\"system\", \"You are a technical support specialist. Provide clear technical guidance.\"),\n",
        "        (\"human\", \"{query}\")\n",
        "    ])\n",
        "    \n",
        "    chain = prompt | llm\n",
        "    result = chain.invoke({\"query\": state[\"query\"]})\n",
        "    \n",
        "    return {\n",
        "        \"response\": result.content,\n",
        "        \"messages\": [AIMessage(content=result.content)]\n",
        "    }\n",
        "\n",
        "# Billing support\n",
        "def billing_support(state: SupportState) -> SupportState:\n",
        "    \"\"\"Handle billing queries.\"\"\"\n",
        "    prompt = ChatPromptTemplate.from_messages([\n",
        "        (\"system\", \"You are a billing specialist. Help with payment and subscription issues.\"),\n",
        "        (\"human\", \"{query}\")\n",
        "    ])\n",
        "    \n",
        "    chain = prompt | llm\n",
        "    result = chain.invoke({\"query\": state[\"query\"]})\n",
        "    \n",
        "    return {\n",
        "        \"response\": result.content,\n",
        "        \"messages\": [AIMessage(content=result.content)]\n",
        "    }\n",
        "\n",
        "# General support\n",
        "def general_support(state: SupportState) -> SupportState:\n",
        "    \"\"\"Handle general queries.\"\"\"\n",
        "    prompt = ChatPromptTemplate.from_messages([\n",
        "        (\"system\", \"You are a helpful customer service agent. Provide friendly assistance.\"),\n",
        "        (\"human\", \"{query}\")\n",
        "    ])\n",
        "    \n",
        "    chain = prompt | llm\n",
        "    result = chain.invoke({\"query\": state[\"query\"]})\n",
        "    \n",
        "    return {\n",
        "        \"response\": result.content,\n",
        "        \"messages\": [AIMessage(content=result.content)]\n",
        "    }\n",
        "\n",
        "# Route based on intent\n",
        "def route_support(state: SupportState) -> str:\n",
        "    \"\"\"Route to appropriate support node.\"\"\"\n",
        "    intent = state[\"intent\"]\n",
        "    if \"technical\" in intent:\n",
        "        return \"technical\"\n",
        "    elif \"billing\" in intent:\n",
        "        return \"billing\"\n",
        "    else:\n",
        "        return \"general\"\n",
        "\n",
        "# Build support graph\n",
        "support_workflow = StateGraph(SupportState)\n",
        "\n",
        "# Add nodes\n",
        "support_workflow.add_node(\"classify\", classify_intent)\n",
        "support_workflow.add_node(\"technical\", technical_support)\n",
        "support_workflow.add_node(\"billing\", billing_support)\n",
        "support_workflow.add_node(\"general\", general_support)\n",
        "\n",
        "# Set entry\n",
        "support_workflow.set_entry_point(\"classify\")\n",
        "\n",
        "# Add conditional routing\n",
        "support_workflow.add_conditional_edges(\n",
        "    \"classify\",\n",
        "    route_support,\n",
        "    {\n",
        "        \"technical\": \"technical\",\n",
        "        \"billing\": \"billing\",\n",
        "        \"general\": \"general\"\n",
        "    }\n",
        ")\n",
        "\n",
        "# All end\n",
        "support_workflow.add_edge(\"technical\", END)\n",
        "support_workflow.add_edge(\"billing\", END)\n",
        "support_workflow.add_edge(\"general\", END)\n",
        "\n",
        "# Compile\n",
        "support_app = support_workflow.compile()\n",
        "\n",
        "print(\"‚úÖ Customer support graph created\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test customer support router\n",
        "test_queries = [\n",
        "    \"My app keeps crashing when I try to upload files\",\n",
        "    \"I was charged twice for my subscription\",\n",
        "    \"What are your business hours?\"\n",
        "]\n",
        "\n",
        "for query in test_queries:\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"‚ùì Query: {query}\")\n",
        "    print()\n",
        "    \n",
        "    result = support_app.invoke({\n",
        "        \"query\": query,\n",
        "        \"messages\": [],\n",
        "        \"intent\": \"\",\n",
        "        \"response\": \"\"\n",
        "    })\n",
        "    \n",
        "    print(f\"üí° Response:\\n{result['response']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# üéØ Summary & Key Takeaways\n",
        "\n",
        "## What We Learned:\n",
        "\n",
        "### 1. **Why LangGraph**\n",
        "- Chains are linear, LangGraph handles complexity\n",
        "- Enables cycles, conditionals, and stateful workflows\n",
        "- Perfect for multi-step agents and iterative tasks\n",
        "\n",
        "### 2. **Core Concepts**\n",
        "- **State:** TypedDict with optional reducers\n",
        "- **Nodes:** Functions that process and update state\n",
        "- **Edges:** Connect nodes (normal and conditional)\n",
        "\n",
        "### 3. **Building Graphs**\n",
        "- StateGraph creation and compilation\n",
        "- Adding nodes and edges\n",
        "- Setting entry points and endpoints\n",
        "- Conditional routing logic\n",
        "\n",
        "### 4. **Advanced Features**\n",
        "- Graph visualization\n",
        "- Streaming execution\n",
        "- Checkpointing and persistence\n",
        "- LLM integration in nodes\n",
        "\n",
        "---\n",
        "\n",
        "## üìù Next Steps:\n",
        "\n",
        "### Exercises for This Week:\n",
        "\n",
        "**Exercise 1 (Due Monday):** `02_exercise_content_moderation.ipynb`\n",
        "- Build content moderation pipeline\n",
        "- Implement multi-check system\n",
        "- Add conditional routing\n",
        "\n",
        "**Exercise 2 (Due Friday):** `03_exercise_research_agent.ipynb`\n",
        "- Create research agent with loops\n",
        "- Implement iterative search\n",
        "- Add quality checks and guardrails\n",
        "\n",
        "---\n",
        "\n",
        "## ü§î Reflection Questions:\n",
        "\n",
        "1. When should you use LangGraph vs LangChain chains?\n",
        "2. How do state reducers work and when are they useful?\n",
        "3. What are the benefits of conditional edges?\n",
        "4. How can checkpointing improve user experience?\n",
        "\n",
        "---\n",
        "\n",
        "## üìö Additional Resources:\n",
        "\n",
        "- [LangGraph Documentation](https://langchain-ai.github.io/langgraph/)\n",
        "- [LangGraph Tutorials](https://github.com/langchain-ai/langgraph/tree/main/examples)\n",
        "- [StateGraph API Reference](https://langchain-ai.github.io/langgraph/reference/graphs/)\n",
        "\n",
        "---\n",
        "\n",
        "**Next Week:** Advanced LangGraph with Human-in-the-Loop! üöÄ"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
